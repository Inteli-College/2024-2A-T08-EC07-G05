{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f826d0-2524-4970-8f63-e1e1c881bf32",
   "metadata": {},
   "source": [
    "# Criação, treino e teste do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f76b5-3009-4b77-84f9-560dab31124b",
   "metadata": {},
   "source": [
    "## Instalando bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2ea2a6-9752-4881-8ecb-ab1b846eccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (74.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (1.66.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae38060-6475-489d-99d2-e0da38622e69",
   "metadata": {},
   "source": [
    "## Leitura e Verificação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9530c490-88ee-4349-9798-281e222e9929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 17:30:33.894411: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-11 17:30:33.902252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-11 17:30:33.911516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-11 17:30:33.914245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-11 17:30:33.921400: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 17:30:34.353890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79857831-cd3e-4781-a548-dce9bff84cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEM_FALHA_ROD\n",
      "0.0    12967\n",
      "1.0      616\n",
      "Name: count, dtype: int64\n",
      "KNR                       0\n",
      "QTD_STATUS_1_OK           0\n",
      "QTD_STATUS_1_NOK          0\n",
      "QTD_STATUS_2_OK           0\n",
      "QTD_STATUS_2_NOK          0\n",
      "QTD_STATUS_718_OK         0\n",
      "QTD_STATUS_718_NOK        0\n",
      "TEMPO_MEDIO               0\n",
      "MOTOR                     0\n",
      "COR                       0\n",
      "QTD_HALLE_                0\n",
      "QTD_HALLE_AGUA            0\n",
      "QTD_HALLE_BUY             0\n",
      "QTD_HALLE_CAB             0\n",
      "QTD_HALLE_DKA             0\n",
      "QTD_HALLE_ESPC            0\n",
      "QTD_HALLE_PROC            0\n",
      "QTD_HALLE_PROF            0\n",
      "QTD_HALLE_PVC             0\n",
      "QTD_HALLE_ROD             0\n",
      "QTD_HALLE_RUID            0\n",
      "QTD_HALLE_TLUI            0\n",
      "QTD_HALLE_ZP5             0\n",
      "QTD_HALLE_ZP5A            0\n",
      "QTD_HALLE_ZP6             0\n",
      "QTD_HALLE_ZP61            0\n",
      "QTD_HALLE_ZP62            0\n",
      "QTD_HALLE_ZP7             0\n",
      "QTD_HALLE_ZP8             0\n",
      "QTD_HALLE_ZP82            0\n",
      "QTD_HALLE_ZP8R            0\n",
      "QTD_SGROUP_#MULTIVALUE    0\n",
      "QTD_SGROUP_-2             0\n",
      "QTD_SGROUP_1              0\n",
      "QTD_SGROUP_133            0\n",
      "QTD_SGROUP_137            0\n",
      "QTD_SGROUP_140            0\n",
      "QTD_SGROUP_2              0\n",
      "QTD_SGROUP_4              0\n",
      "QTD_SGROUP_5              0\n",
      "QTD_SGROUP_9830946        0\n",
      "TEM_FALHA_ROD             0\n",
      "ZP5_MIN                   0\n",
      "ZP5A_MIN                  0\n",
      "ZP61_MIN                  0\n",
      "ZP6 / ZP62_MIN            0\n",
      "CAB_MIN                   0\n",
      "dtype: int64\n",
      "\n",
      "----------\n",
      "\n",
      "\n",
      "----------\n",
      "\n",
      "TEM_FALHA_ROD\n",
      "0.0    12967\n",
      "1.0      616\n",
      "Name: count, dtype: int64\n",
      "KNR                       0\n",
      "QTD_STATUS_1_OK           0\n",
      "QTD_STATUS_1_NOK          0\n",
      "QTD_STATUS_2_OK           0\n",
      "QTD_STATUS_2_NOK          0\n",
      "QTD_STATUS_718_OK         0\n",
      "QTD_STATUS_718_NOK        0\n",
      "TEMPO_MEDIO               0\n",
      "MOTOR                     0\n",
      "COR                       0\n",
      "QTD_HALLE_                0\n",
      "QTD_HALLE_BUY             0\n",
      "QTD_HALLE_CAB             0\n",
      "QTD_HALLE_DKA             0\n",
      "QTD_HALLE_ESPC            0\n",
      "QTD_HALLE_PROC            0\n",
      "QTD_HALLE_PROF            0\n",
      "QTD_HALLE_PVC             0\n",
      "QTD_HALLE_RUID            0\n",
      "QTD_HALLE_TLUI            0\n",
      "QTD_HALLE_ZP5             0\n",
      "QTD_HALLE_ZP5A            0\n",
      "QTD_HALLE_ZP6             0\n",
      "QTD_HALLE_ZP61            0\n",
      "QTD_HALLE_ZP62            0\n",
      "QTD_HALLE_ZP7             0\n",
      "QTD_HALLE_ZP82            0\n",
      "QTD_SGROUP_#MULTIVALUE    0\n",
      "QTD_SGROUP_-2             0\n",
      "QTD_SGROUP_1              0\n",
      "QTD_SGROUP_133            0\n",
      "QTD_SGROUP_137            0\n",
      "QTD_SGROUP_140            0\n",
      "QTD_SGROUP_2              0\n",
      "QTD_SGROUP_4              0\n",
      "QTD_SGROUP_5              0\n",
      "QTD_SGROUP_9830946        0\n",
      "TEM_FALHA_ROD             0\n",
      "ZP5_MIN                   0\n",
      "ZP5A_MIN                  0\n",
      "ZP61_MIN                  0\n",
      "ZP6 / ZP62_MIN            0\n",
      "CAB_MIN                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "comum = pd.read_parquet('DF_KNRS_COMUM_PROCESSADO.parquet')\n",
    "tempo = pd.read_parquet('tempo_de_cada_knr_por_halle.parquet')\n",
    "\n",
    "df = comum.merge(tempo, on='KNR', how='right')\n",
    "df = df.dropna()\n",
    "print(df['TEM_FALHA_ROD'].value_counts())  # Verificando a distribuição da variável alvo\n",
    "print(df.isnull().sum())\n",
    "print('\\n----------\\n')\n",
    "\n",
    "df = df.dropna()  # Removendo valores nulos\n",
    "df = df.drop(columns=[\"QTD_HALLE_ROD\", \"QTD_HALLE_AGUA\", \"QTD_HALLE_ZP8\", \"QTD_HALLE_ZP8R\"])\n",
    "\n",
    "print('\\n----------\\n')\n",
    "print(df['TEM_FALHA_ROD'].value_counts())  # Verificando a distribuição da variável alvo\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7708be56-f646-42da-a8f9-224406f32009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorrências de valor 1 na coluna QTD_HALLE_ESPC: 248\n"
     ]
    }
   ],
   "source": [
    "qtd_ocorrencias = df[df['QTD_HALLE_ESPC'] > 1].shape[0]\n",
    "print(f\"Ocorrências de valor 1 na coluna QTD_HALLE_ESPC: {qtd_ocorrencias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e807317b-f6b1-459e-a618-3e51ffcfe111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNR</th>\n",
       "      <th>QTD_STATUS_1_OK</th>\n",
       "      <th>QTD_STATUS_1_NOK</th>\n",
       "      <th>QTD_STATUS_2_OK</th>\n",
       "      <th>QTD_STATUS_2_NOK</th>\n",
       "      <th>QTD_STATUS_718_OK</th>\n",
       "      <th>QTD_STATUS_718_NOK</th>\n",
       "      <th>TEMPO_MEDIO</th>\n",
       "      <th>MOTOR</th>\n",
       "      <th>COR</th>\n",
       "      <th>...</th>\n",
       "      <th>QTD_SGROUP_2</th>\n",
       "      <th>QTD_SGROUP_4</th>\n",
       "      <th>QTD_SGROUP_5</th>\n",
       "      <th>QTD_SGROUP_9830946</th>\n",
       "      <th>TEM_FALHA_ROD</th>\n",
       "      <th>ZP5_MIN</th>\n",
       "      <th>ZP5A_MIN</th>\n",
       "      <th>ZP61_MIN</th>\n",
       "      <th>ZP6 / ZP62_MIN</th>\n",
       "      <th>CAB_MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>2023-3016123</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.883333</td>\n",
       "      <td>CWL</td>\n",
       "      <td>2R2R</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1740.483333</td>\n",
       "      <td>5605.383333</td>\n",
       "      <td>102.200000</td>\n",
       "      <td>25.883333</td>\n",
       "      <td>57.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6891</th>\n",
       "      <td>2023-3016123</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.250000</td>\n",
       "      <td>CWL</td>\n",
       "      <td>2R2R</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1740.483333</td>\n",
       "      <td>5605.383333</td>\n",
       "      <td>102.200000</td>\n",
       "      <td>25.883333</td>\n",
       "      <td>57.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>2023-3016194</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.683333</td>\n",
       "      <td>DHS</td>\n",
       "      <td>0Q0Q</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2582.033333</td>\n",
       "      <td>5817.316667</td>\n",
       "      <td>53.133333</td>\n",
       "      <td>23.350000</td>\n",
       "      <td>11454.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>2023-3016194</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73.350000</td>\n",
       "      <td>DHS</td>\n",
       "      <td>0Q0Q</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2582.033333</td>\n",
       "      <td>5817.316667</td>\n",
       "      <td>53.133333</td>\n",
       "      <td>23.350000</td>\n",
       "      <td>11454.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7252</th>\n",
       "      <td>2023-3026027</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.633333</td>\n",
       "      <td>DHS</td>\n",
       "      <td>2R2R</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1772.450000</td>\n",
       "      <td>5611.933333</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>25.966667</td>\n",
       "      <td>4538.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               KNR  QTD_STATUS_1_OK  QTD_STATUS_1_NOK  QTD_STATUS_2_OK  \\\n",
       "6890  2023-3016123              7.0               0.0            840.0   \n",
       "6891  2023-3016123              7.0               0.0            803.0   \n",
       "7010  2023-3016194              7.0               0.0            846.0   \n",
       "7011  2023-3016194              7.0               0.0            802.0   \n",
       "7252  2023-3026027              7.0               0.0            850.0   \n",
       "\n",
       "      QTD_STATUS_2_NOK  QTD_STATUS_718_OK  QTD_STATUS_718_NOK  TEMPO_MEDIO  \\\n",
       "6890               0.0               50.0                 1.0    50.883333   \n",
       "6891               0.0               48.0                 1.0    92.250000   \n",
       "7010               9.0               58.0                 2.0    52.683333   \n",
       "7011               9.0               56.0                 2.0    73.350000   \n",
       "7252               6.0               53.0                 4.0    48.633333   \n",
       "\n",
       "     MOTOR   COR  ...  QTD_SGROUP_2  QTD_SGROUP_4  QTD_SGROUP_5  \\\n",
       "6890   CWL  2R2R  ...           3.0           1.0           0.0   \n",
       "6891   CWL  2R2R  ...           3.0           1.0           0.0   \n",
       "7010   DHS  0Q0Q  ...           7.0           2.0           0.0   \n",
       "7011   DHS  0Q0Q  ...           7.0           2.0           0.0   \n",
       "7252   DHS  2R2R  ...           7.0           3.0           0.0   \n",
       "\n",
       "      QTD_SGROUP_9830946  TEM_FALHA_ROD      ZP5_MIN     ZP5A_MIN    ZP61_MIN  \\\n",
       "6890                 0.0            1.0  1740.483333  5605.383333  102.200000   \n",
       "6891                 0.0            1.0  1740.483333  5605.383333  102.200000   \n",
       "7010                 0.0            0.0  2582.033333  5817.316667   53.133333   \n",
       "7011                 0.0            0.0  2582.033333  5817.316667   53.133333   \n",
       "7252                 0.0            0.0  1772.450000  5611.933333   36.833333   \n",
       "\n",
       "      ZP6 / ZP62_MIN       CAB_MIN  \n",
       "6890       25.883333     57.666667  \n",
       "6891       25.883333     57.666667  \n",
       "7010       23.350000  11454.383333  \n",
       "7011       23.350000  11454.383333  \n",
       "7252       25.966667   4538.233333  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6230e2-5f04-4982-96b9-6d8b87fd2862",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1534e9fd-0ea5-48c8-b7fa-700076499a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Criando variáveis dummies\n",
    "df = pd.get_dummies(df, columns=['COR', 'MOTOR'], drop_first=True)\n",
    "\n",
    "# Removendo colunas desnecessárias\n",
    "df = df.drop(columns=[\"KNR\"])\n",
    "\n",
    "\n",
    "# Exemplo de DataFrame com colunas numéricas e de string\n",
    "# Suponha que df seja o seu DataFrame original\n",
    "\n",
    "# Separar as colunas numéricas\n",
    "df_numerical = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Separar as colunas não numéricas\n",
    "df_non_numerical = df.select_dtypes(exclude=['float64', 'int64'])\n",
    "\n",
    "# Aplicar o MinMaxScaler nas colunas numéricas\n",
    "scaler = MinMaxScaler()\n",
    "df_numerical_scaled = pd.DataFrame(scaler.fit_transform(df_numerical), columns=df_numerical.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f57c664d-7338-48bb-86f7-19983ff951cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QTD_STATUS_1_OK</th>\n",
       "      <th>QTD_STATUS_1_NOK</th>\n",
       "      <th>QTD_STATUS_2_OK</th>\n",
       "      <th>QTD_STATUS_2_NOK</th>\n",
       "      <th>QTD_STATUS_718_OK</th>\n",
       "      <th>QTD_STATUS_718_NOK</th>\n",
       "      <th>TEMPO_MEDIO</th>\n",
       "      <th>QTD_HALLE_</th>\n",
       "      <th>QTD_HALLE_BUY</th>\n",
       "      <th>QTD_HALLE_CAB</th>\n",
       "      <th>...</th>\n",
       "      <th>QTD_SGROUP_2</th>\n",
       "      <th>QTD_SGROUP_4</th>\n",
       "      <th>QTD_SGROUP_5</th>\n",
       "      <th>QTD_SGROUP_9830946</th>\n",
       "      <th>TEM_FALHA_ROD</th>\n",
       "      <th>ZP5_MIN</th>\n",
       "      <th>ZP5A_MIN</th>\n",
       "      <th>ZP61_MIN</th>\n",
       "      <th>ZP6 / ZP62_MIN</th>\n",
       "      <th>CAB_MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.103751</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.719534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.103751</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041130</td>\n",
       "      <td>0.107964</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.520787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718638</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.294737</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041130</td>\n",
       "      <td>0.107964</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.520787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761649</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.103882</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.206273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   QTD_STATUS_1_OK  QTD_STATUS_1_NOK  QTD_STATUS_2_OK  QTD_STATUS_2_NOK  \\\n",
       "0         0.466667               0.0         0.752688          0.000000   \n",
       "1         0.466667               0.0         0.719534          0.000000   \n",
       "2         0.466667               0.0         0.758065          0.089109   \n",
       "3         0.466667               0.0         0.718638          0.089109   \n",
       "4         0.466667               0.0         0.761649          0.059406   \n",
       "\n",
       "   QTD_STATUS_718_OK  QTD_STATUS_718_NOK  TEMPO_MEDIO  QTD_HALLE_  \\\n",
       "0           0.263158            0.014085     0.002383         0.0   \n",
       "1           0.252632            0.014085     0.004320         0.0   \n",
       "2           0.305263            0.028169     0.002467         0.0   \n",
       "3           0.294737            0.028169     0.003435         0.0   \n",
       "4           0.278947            0.056338     0.002277         0.0   \n",
       "\n",
       "   QTD_HALLE_BUY  QTD_HALLE_CAB  ...  QTD_SGROUP_2  QTD_SGROUP_4  \\\n",
       "0            0.0            0.0  ...      0.157895      0.055556   \n",
       "1            0.0            0.0  ...      0.157895      0.055556   \n",
       "2            0.0            0.0  ...      0.368421      0.111111   \n",
       "3            0.0            0.0  ...      0.368421      0.111111   \n",
       "4            0.0            0.0  ...      0.368421      0.166667   \n",
       "\n",
       "   QTD_SGROUP_5  QTD_SGROUP_9830946  TEM_FALHA_ROD   ZP5_MIN  ZP5A_MIN  \\\n",
       "0           0.0                 0.0            1.0  0.022740  0.103751   \n",
       "1           0.0                 0.0            1.0  0.022740  0.103751   \n",
       "2           0.0                 0.0            0.0  0.041130  0.107964   \n",
       "3           0.0                 0.0            0.0  0.041130  0.107964   \n",
       "4           0.0                 0.0            0.0  0.023439  0.103882   \n",
       "\n",
       "   ZP61_MIN  ZP6 / ZP62_MIN   CAB_MIN  \n",
       "0  0.005534        0.000860  0.002519  \n",
       "1  0.005534        0.000860  0.002519  \n",
       "2  0.002762        0.000749  0.520787  \n",
       "3  0.002762        0.000749  0.520787  \n",
       "4  0.001841        0.000864  0.206273  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numerical_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0728d-c613-41c0-86ff-0cbe3cd64412",
   "metadata": {},
   "source": [
    "## Balanceamento das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5860eb-baaa-40cb-8650-ec93578b031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df_numerical_scaled.drop(columns=['TEM_FALHA_ROD'])  # Removendo a variável alvo, mantendo apenas as variáveis preditoras\n",
    "y = df_numerical_scaled['TEM_FALHA_ROD']  # Definindo a variável alvo\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)# Initialize SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)# Apply SMOTE to the training data\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e0369-dc35-4611-a33f-420b359864fe",
   "metadata": {},
   "source": [
    "## Dividindo o dataset entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a580506-0e4a-4601-8477-016b0c7d2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Importa a função para dividir os dados em conjuntos de treino e teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  \n",
    "# Divide os dados balanceados em conjuntos de treino (80%) e teste (20%), com uma semente de aleatoriedade fixa para reprodução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384f474-74f4-49e7-9eff-bfb02d435da1",
   "metadata": {},
   "source": [
    "## Redimensionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696c092c-acb2-4863-9ae2-35b197f871fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))  \n",
    "# Altera a forma de X_train para (n amostras, 1, n características) para compatibilidade com redes neurais que esperam uma dimensão adicional\n",
    "\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))  \n",
    "# Altera a forma de X_test de maneira semelhante\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)  \n",
    "# Converte X_train para um array NumPy com tipo de dado float32\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.float32)  \n",
    "# Converte y_train para um array NumPy com tipo de dado float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2858d-ca75-4d6e-a837-c6f4e781a0ae",
   "metadata": {},
   "source": [
    "## Construção dos Modelos (LSTM e GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b850a-75fc-458a-8270-c7d1669228fb",
   "metadata": {},
   "source": [
    "### Modelo GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f65e3a-c828-4360-b810-2aa6a274e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726086636.440172   85277 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-11 17:30:36.456954: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/crz/Github/2024-2A-T08-EC07-G05/venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential()  # Cria um modelo sequencial, que é uma pilha linear de camadas\n",
    "\n",
    "model_gru.add(GRU(50, input_shape=(X_train.shape[1], X_train.shape[2])))  \n",
    "# Adiciona uma camada GRU com 50 unidades. A forma de entrada é (n timesteps, n características)\n",
    "\n",
    "model_gru.add(Dropout(0.2))  \n",
    "# Adiciona uma camada Dropout para prevenir overfitting, desativando aleatoriamente 20% dos neurônios durante o treinamento\n",
    "\n",
    "model_gru.add(Dense(1, activation='sigmoid'))  \n",
    "# Adiciona uma camada densa de saída com 1 neurônio e ativação sigmoide para uma tarefa de classificação binária\n",
    "\n",
    "model_gru.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "# Compila o modelo usando o otimizador Adam com taxa de aprendizado de 0.001, a função de perda de entropia cruzada binária e a métrica de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69a1d73-5e39-43cb-934b-d8eb3e4bf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5425 - loss: 0.6886 - val_accuracy: 0.6334 - val_loss: 0.6668\n",
      "Epoch 2/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.6294 - loss: 0.6632 - val_accuracy: 0.6778 - val_loss: 0.6265\n",
      "Epoch 3/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.6756 - loss: 0.6288 - val_accuracy: 0.7246 - val_loss: 0.5896\n",
      "Epoch 4/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.7142 - loss: 0.5989 - val_accuracy: 0.7631 - val_loss: 0.5555\n",
      "Epoch 5/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.7522 - loss: 0.5602 - val_accuracy: 0.8367 - val_loss: 0.4997\n",
      "Epoch 6/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.8261 - loss: 0.5053 - val_accuracy: 0.8910 - val_loss: 0.4425\n",
      "Epoch 7/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.8813 - loss: 0.4442 - val_accuracy: 0.9285 - val_loss: 0.3845\n",
      "Epoch 8/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9162 - loss: 0.3904 - val_accuracy: 0.9395 - val_loss: 0.3340\n",
      "Epoch 9/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9309 - loss: 0.3418 - val_accuracy: 0.9453 - val_loss: 0.2963\n",
      "Epoch 10/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9432 - loss: 0.3019 - val_accuracy: 0.9605 - val_loss: 0.2542\n",
      "Epoch 11/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9520 - loss: 0.2663 - val_accuracy: 0.9594 - val_loss: 0.2283\n",
      "Epoch 12/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9545 - loss: 0.2399 - val_accuracy: 0.9635 - val_loss: 0.2090\n",
      "Epoch 13/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.9566 - loss: 0.2280 - val_accuracy: 0.9660 - val_loss: 0.1920\n",
      "Epoch 14/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9573 - loss: 0.2132 - val_accuracy: 0.9649 - val_loss: 0.1777\n",
      "Epoch 15/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9591 - loss: 0.2005 - val_accuracy: 0.9608 - val_loss: 0.1853\n",
      "Epoch 16/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9587 - loss: 0.1963 - val_accuracy: 0.9625 - val_loss: 0.1717\n",
      "Epoch 17/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9585 - loss: 0.1927 - val_accuracy: 0.9649 - val_loss: 0.1694\n",
      "Epoch 18/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9595 - loss: 0.1835 - val_accuracy: 0.9653 - val_loss: 0.1704\n",
      "Epoch 19/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9604 - loss: 0.1796 - val_accuracy: 0.9656 - val_loss: 0.1636\n",
      "Epoch 20/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9631 - loss: 0.1846 - val_accuracy: 0.9522 - val_loss: 0.1867\n",
      "Epoch 21/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9620 - loss: 0.1679 - val_accuracy: 0.9666 - val_loss: 0.1540\n",
      "Epoch 22/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9596 - loss: 0.1710 - val_accuracy: 0.9642 - val_loss: 0.1501\n",
      "Epoch 23/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9619 - loss: 0.1772 - val_accuracy: 0.9677 - val_loss: 0.1510\n",
      "Epoch 24/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9603 - loss: 0.1937 - val_accuracy: 0.9646 - val_loss: 0.1531\n",
      "Epoch 25/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9553 - loss: 0.1931 - val_accuracy: 0.9663 - val_loss: 0.1481\n",
      "Epoch 26/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9631 - loss: 0.1664 - val_accuracy: 0.9670 - val_loss: 0.1470\n",
      "Epoch 27/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9604 - loss: 0.1642 - val_accuracy: 0.9649 - val_loss: 0.1573\n",
      "Epoch 28/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9566 - loss: 0.1831 - val_accuracy: 0.9677 - val_loss: 0.1464\n",
      "Epoch 29/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9560 - loss: 0.1864 - val_accuracy: 0.9673 - val_loss: 0.1453\n",
      "Epoch 30/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9606 - loss: 0.1684 - val_accuracy: 0.9660 - val_loss: 0.1548\n",
      "Epoch 31/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9590 - loss: 0.1837 - val_accuracy: 0.9639 - val_loss: 0.1566\n",
      "Epoch 32/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9588 - loss: 0.1686 - val_accuracy: 0.9677 - val_loss: 0.1453\n",
      "Epoch 33/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9631 - loss: 0.1737 - val_accuracy: 0.9653 - val_loss: 0.1457\n",
      "Epoch 34/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9587 - loss: 0.1763 - val_accuracy: 0.9598 - val_loss: 0.1633\n",
      "Epoch 35/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9612 - loss: 0.1704 - val_accuracy: 0.9670 - val_loss: 0.1468\n",
      "Epoch 36/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9619 - loss: 0.1684 - val_accuracy: 0.9660 - val_loss: 0.1559\n",
      "Epoch 37/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9588 - loss: 0.1786 - val_accuracy: 0.9666 - val_loss: 0.1490\n",
      "Epoch 38/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9629 - loss: 0.1615 - val_accuracy: 0.9680 - val_loss: 0.1452\n",
      "Epoch 39/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9616 - loss: 0.1811 - val_accuracy: 0.9670 - val_loss: 0.1440\n",
      "Epoch 40/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9619 - loss: 0.1875 - val_accuracy: 0.9673 - val_loss: 0.1490\n",
      "Epoch 41/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.9608 - loss: 0.1674 - val_accuracy: 0.9677 - val_loss: 0.1438\n",
      "Epoch 42/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9587 - loss: 0.1842 - val_accuracy: 0.9677 - val_loss: 0.1444\n",
      "Epoch 43/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9622 - loss: 0.1736 - val_accuracy: 0.9639 - val_loss: 0.1523\n",
      "Epoch 44/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9620 - loss: 0.1684 - val_accuracy: 0.9584 - val_loss: 0.1641\n",
      "Epoch 45/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9624 - loss: 0.1651 - val_accuracy: 0.9673 - val_loss: 0.1420\n",
      "Epoch 46/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9588 - loss: 0.1736 - val_accuracy: 0.9677 - val_loss: 0.1418\n",
      "Epoch 47/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9611 - loss: 0.1655 - val_accuracy: 0.9684 - val_loss: 0.1434\n",
      "Epoch 48/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9638 - loss: 0.1656 - val_accuracy: 0.9673 - val_loss: 0.1441\n",
      "Epoch 49/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9580 - loss: 0.1733 - val_accuracy: 0.9687 - val_loss: 0.1411\n",
      "Epoch 50/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9600 - loss: 0.1760 - val_accuracy: 0.9656 - val_loss: 0.1438\n",
      "Epoch 51/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9626 - loss: 0.1587 - val_accuracy: 0.9684 - val_loss: 0.1404\n",
      "Epoch 52/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9615 - loss: 0.1768 - val_accuracy: 0.9594 - val_loss: 0.1624\n",
      "Epoch 53/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.9630 - loss: 0.1712 - val_accuracy: 0.9687 - val_loss: 0.1392\n",
      "Epoch 54/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9626 - loss: 0.1603 - val_accuracy: 0.9687 - val_loss: 0.1404\n",
      "Epoch 55/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9627 - loss: 0.1679 - val_accuracy: 0.9691 - val_loss: 0.1393\n",
      "Epoch 56/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9653 - loss: 0.1607 - val_accuracy: 0.9684 - val_loss: 0.1399\n",
      "Epoch 57/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9622 - loss: 0.1575 - val_accuracy: 0.9670 - val_loss: 0.1411\n",
      "Epoch 58/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9654 - loss: 0.1702 - val_accuracy: 0.9697 - val_loss: 0.1380\n",
      "Epoch 59/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9623 - loss: 0.1697 - val_accuracy: 0.9708 - val_loss: 0.1367\n",
      "Epoch 60/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.9642 - loss: 0.1596 - val_accuracy: 0.9697 - val_loss: 0.1394\n",
      "Epoch 61/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.9637 - loss: 0.1636 - val_accuracy: 0.9684 - val_loss: 0.1378\n",
      "Epoch 62/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9613 - loss: 0.1595 - val_accuracy: 0.9684 - val_loss: 0.1413\n",
      "Epoch 63/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9649 - loss: 0.1529 - val_accuracy: 0.9697 - val_loss: 0.1382\n",
      "Epoch 64/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9638 - loss: 0.1631 - val_accuracy: 0.9691 - val_loss: 0.1407\n",
      "Epoch 65/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9639 - loss: 0.1620 - val_accuracy: 0.9694 - val_loss: 0.1361\n",
      "Epoch 66/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9616 - loss: 0.1614 - val_accuracy: 0.9691 - val_loss: 0.1385\n",
      "Epoch 67/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9658 - loss: 0.1502 - val_accuracy: 0.9697 - val_loss: 0.1397\n",
      "Epoch 68/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.9669 - loss: 0.1527 - val_accuracy: 0.9694 - val_loss: 0.1352\n",
      "Epoch 69/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9647 - loss: 0.1506 - val_accuracy: 0.9711 - val_loss: 0.1404\n",
      "Epoch 70/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9643 - loss: 0.1716 - val_accuracy: 0.9691 - val_loss: 0.1385\n",
      "Epoch 71/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9649 - loss: 0.1554 - val_accuracy: 0.9694 - val_loss: 0.1339\n",
      "Epoch 72/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9658 - loss: 0.1522 - val_accuracy: 0.9708 - val_loss: 0.1339\n",
      "Epoch 73/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9666 - loss: 0.1426 - val_accuracy: 0.9697 - val_loss: 0.1342\n",
      "Epoch 74/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9654 - loss: 0.1500 - val_accuracy: 0.9704 - val_loss: 0.1324\n",
      "Epoch 75/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9672 - loss: 0.1476 - val_accuracy: 0.9701 - val_loss: 0.1325\n",
      "Epoch 76/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9663 - loss: 0.1507 - val_accuracy: 0.9711 - val_loss: 0.1316\n",
      "Epoch 77/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.9661 - loss: 0.1413 - val_accuracy: 0.9687 - val_loss: 0.1376\n",
      "Epoch 78/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9647 - loss: 0.1558 - val_accuracy: 0.9715 - val_loss: 0.1351\n",
      "Epoch 79/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9662 - loss: 0.1482 - val_accuracy: 0.9704 - val_loss: 0.1312\n",
      "Epoch 80/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9680 - loss: 0.1476 - val_accuracy: 0.9701 - val_loss: 0.1326\n",
      "Epoch 81/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9688 - loss: 0.1391 - val_accuracy: 0.9680 - val_loss: 0.1385\n",
      "Epoch 82/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9707 - loss: 0.1394 - val_accuracy: 0.9718 - val_loss: 0.1322\n",
      "Epoch 83/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9642 - loss: 0.1599 - val_accuracy: 0.9721 - val_loss: 0.1299\n",
      "Epoch 84/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9647 - loss: 0.1507 - val_accuracy: 0.9718 - val_loss: 0.1294\n",
      "Epoch 85/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9676 - loss: 0.1510 - val_accuracy: 0.9721 - val_loss: 0.1311\n",
      "Epoch 86/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9695 - loss: 0.1319 - val_accuracy: 0.9632 - val_loss: 0.1516\n",
      "Epoch 87/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9647 - loss: 0.1449 - val_accuracy: 0.9735 - val_loss: 0.1285\n",
      "Epoch 88/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9685 - loss: 0.1395 - val_accuracy: 0.9715 - val_loss: 0.1280\n",
      "Epoch 89/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9687 - loss: 0.1431 - val_accuracy: 0.9739 - val_loss: 0.1279\n",
      "Epoch 90/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9689 - loss: 0.1493 - val_accuracy: 0.9735 - val_loss: 0.1282\n",
      "Epoch 91/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9675 - loss: 0.1398 - val_accuracy: 0.9746 - val_loss: 0.1302\n",
      "Epoch 92/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9677 - loss: 0.1443 - val_accuracy: 0.9715 - val_loss: 0.1329\n",
      "Epoch 93/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9688 - loss: 0.1523 - val_accuracy: 0.9742 - val_loss: 0.1271\n",
      "Epoch 94/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9674 - loss: 0.1450 - val_accuracy: 0.9715 - val_loss: 0.1359\n",
      "Epoch 95/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9720 - loss: 0.1268 - val_accuracy: 0.9721 - val_loss: 0.1286\n",
      "Epoch 96/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9679 - loss: 0.1367 - val_accuracy: 0.9704 - val_loss: 0.1378\n",
      "Epoch 97/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9668 - loss: 0.1530 - val_accuracy: 0.9715 - val_loss: 0.1328\n",
      "Epoch 98/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9684 - loss: 0.1406 - val_accuracy: 0.9739 - val_loss: 0.1251\n",
      "Epoch 99/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.9703 - loss: 0.1359 - val_accuracy: 0.9728 - val_loss: 0.1282\n",
      "Epoch 100/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9717 - loss: 0.1358 - val_accuracy: 0.9752 - val_loss: 0.1262\n",
      "Epoch 101/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9720 - loss: 0.1278 - val_accuracy: 0.9732 - val_loss: 0.1318\n",
      "Epoch 102/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9689 - loss: 0.1392 - val_accuracy: 0.9728 - val_loss: 0.1280\n",
      "Epoch 103/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9711 - loss: 0.1364 - val_accuracy: 0.9739 - val_loss: 0.1249\n",
      "Epoch 104/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9703 - loss: 0.1300 - val_accuracy: 0.9732 - val_loss: 0.1239\n",
      "Epoch 105/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.9706 - loss: 0.1394 - val_accuracy: 0.9735 - val_loss: 0.1244\n",
      "Epoch 106/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9695 - loss: 0.1462 - val_accuracy: 0.9756 - val_loss: 0.1251\n",
      "Epoch 107/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9708 - loss: 0.1305 - val_accuracy: 0.9728 - val_loss: 0.1248\n",
      "Epoch 108/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9681 - loss: 0.1534 - val_accuracy: 0.9742 - val_loss: 0.1217\n",
      "Epoch 109/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9690 - loss: 0.1438 - val_accuracy: 0.9739 - val_loss: 0.1212\n",
      "Epoch 110/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9696 - loss: 0.1343 - val_accuracy: 0.9752 - val_loss: 0.1233\n",
      "Epoch 111/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9720 - loss: 0.1356 - val_accuracy: 0.9739 - val_loss: 0.1222\n",
      "Epoch 112/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9698 - loss: 0.1352 - val_accuracy: 0.9749 - val_loss: 0.1209\n",
      "Epoch 113/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9694 - loss: 0.1352 - val_accuracy: 0.9735 - val_loss: 0.1209\n",
      "Epoch 114/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9704 - loss: 0.1369 - val_accuracy: 0.9742 - val_loss: 0.1211\n",
      "Epoch 115/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9683 - loss: 0.1365 - val_accuracy: 0.9746 - val_loss: 0.1202\n",
      "Epoch 116/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9711 - loss: 0.1293 - val_accuracy: 0.9742 - val_loss: 0.1220\n",
      "Epoch 117/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.9697 - loss: 0.1280 - val_accuracy: 0.9742 - val_loss: 0.1204\n",
      "Epoch 118/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9717 - loss: 0.1247 - val_accuracy: 0.9749 - val_loss: 0.1196\n",
      "Epoch 119/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9705 - loss: 0.1325 - val_accuracy: 0.9746 - val_loss: 0.1198\n",
      "Epoch 120/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9703 - loss: 0.1361 - val_accuracy: 0.9756 - val_loss: 0.1234\n",
      "Epoch 121/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9731 - loss: 0.1258 - val_accuracy: 0.9739 - val_loss: 0.1334\n",
      "Epoch 122/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9695 - loss: 0.1386 - val_accuracy: 0.9756 - val_loss: 0.1200\n",
      "Epoch 123/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9734 - loss: 0.1228 - val_accuracy: 0.9752 - val_loss: 0.1188\n",
      "Epoch 124/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9701 - loss: 0.1262 - val_accuracy: 0.9752 - val_loss: 0.1173\n",
      "Epoch 125/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9698 - loss: 0.1311 - val_accuracy: 0.9749 - val_loss: 0.1216\n",
      "Epoch 126/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9715 - loss: 0.1228 - val_accuracy: 0.9766 - val_loss: 0.1196\n",
      "Epoch 127/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9725 - loss: 0.1243 - val_accuracy: 0.9756 - val_loss: 0.1178\n",
      "Epoch 128/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9727 - loss: 0.1312 - val_accuracy: 0.9752 - val_loss: 0.1168\n",
      "Epoch 129/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9710 - loss: 0.1279 - val_accuracy: 0.9742 - val_loss: 0.1225\n",
      "Epoch 130/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.9708 - loss: 0.1393 - val_accuracy: 0.9752 - val_loss: 0.1175\n",
      "Epoch 131/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9727 - loss: 0.1216 - val_accuracy: 0.9746 - val_loss: 0.1184\n",
      "Epoch 132/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9711 - loss: 0.1273 - val_accuracy: 0.9756 - val_loss: 0.1194\n",
      "Epoch 133/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9726 - loss: 0.1197 - val_accuracy: 0.9759 - val_loss: 0.1153\n",
      "Epoch 134/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9721 - loss: 0.1212 - val_accuracy: 0.9763 - val_loss: 0.1177\n",
      "Epoch 135/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9694 - loss: 0.1396 - val_accuracy: 0.9742 - val_loss: 0.1218\n",
      "Epoch 136/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9722 - loss: 0.1296 - val_accuracy: 0.9763 - val_loss: 0.1161\n",
      "Epoch 137/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9728 - loss: 0.1237 - val_accuracy: 0.9756 - val_loss: 0.1162\n",
      "Epoch 138/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9705 - loss: 0.1334 - val_accuracy: 0.9763 - val_loss: 0.1145\n",
      "Epoch 139/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9726 - loss: 0.1225 - val_accuracy: 0.9756 - val_loss: 0.1162\n",
      "Epoch 140/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9742 - loss: 0.1177 - val_accuracy: 0.9763 - val_loss: 0.1158\n",
      "Epoch 141/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9737 - loss: 0.1169 - val_accuracy: 0.9763 - val_loss: 0.1156\n",
      "Epoch 142/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9728 - loss: 0.1151 - val_accuracy: 0.9756 - val_loss: 0.1160\n",
      "Epoch 143/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9738 - loss: 0.1186 - val_accuracy: 0.9752 - val_loss: 0.1151\n",
      "Epoch 144/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.9732 - loss: 0.1218 - val_accuracy: 0.9759 - val_loss: 0.1144\n",
      "Epoch 145/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9694 - loss: 0.1234 - val_accuracy: 0.9756 - val_loss: 0.1146\n",
      "Epoch 146/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9739 - loss: 0.1296 - val_accuracy: 0.9759 - val_loss: 0.1162\n",
      "Epoch 147/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9721 - loss: 0.1259 - val_accuracy: 0.9763 - val_loss: 0.1149\n",
      "Epoch 148/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9747 - loss: 0.1199 - val_accuracy: 0.9759 - val_loss: 0.1151\n",
      "Epoch 149/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9754 - loss: 0.1109 - val_accuracy: 0.9756 - val_loss: 0.1161\n",
      "Epoch 150/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9735 - loss: 0.1250 - val_accuracy: 0.9759 - val_loss: 0.1155\n",
      "Epoch 151/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9760 - loss: 0.1109 - val_accuracy: 0.9759 - val_loss: 0.1138\n",
      "Epoch 152/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9748 - loss: 0.1116 - val_accuracy: 0.9752 - val_loss: 0.1196\n",
      "Epoch 153/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9737 - loss: 0.1129 - val_accuracy: 0.9763 - val_loss: 0.1137\n",
      "Epoch 154/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9742 - loss: 0.1111 - val_accuracy: 0.9759 - val_loss: 0.1149\n",
      "Epoch 155/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9732 - loss: 0.1143 - val_accuracy: 0.9763 - val_loss: 0.1160\n",
      "Epoch 156/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9747 - loss: 0.1142 - val_accuracy: 0.9759 - val_loss: 0.1155\n",
      "Epoch 157/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.9734 - loss: 0.1144 - val_accuracy: 0.9763 - val_loss: 0.1126\n",
      "Epoch 158/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9728 - loss: 0.1192 - val_accuracy: 0.9759 - val_loss: 0.1123\n",
      "Epoch 159/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9719 - loss: 0.1246 - val_accuracy: 0.9752 - val_loss: 0.1180\n",
      "Epoch 160/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9748 - loss: 0.1145 - val_accuracy: 0.9766 - val_loss: 0.1130\n",
      "Epoch 161/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9732 - loss: 0.1177 - val_accuracy: 0.9746 - val_loss: 0.1189\n",
      "Epoch 162/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9740 - loss: 0.1184 - val_accuracy: 0.9766 - val_loss: 0.1122\n",
      "Epoch 163/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.9763 - loss: 0.1069 - val_accuracy: 0.9752 - val_loss: 0.1182\n",
      "Epoch 164/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9722 - loss: 0.1132 - val_accuracy: 0.9763 - val_loss: 0.1118\n",
      "Epoch 165/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9725 - loss: 0.1136 - val_accuracy: 0.9759 - val_loss: 0.1131\n",
      "Epoch 166/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9758 - loss: 0.1068 - val_accuracy: 0.9763 - val_loss: 0.1116\n",
      "Epoch 167/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9734 - loss: 0.1244 - val_accuracy: 0.9763 - val_loss: 0.1120\n",
      "Epoch 168/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9733 - loss: 0.1199 - val_accuracy: 0.9756 - val_loss: 0.1130\n",
      "Epoch 169/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9731 - loss: 0.1198 - val_accuracy: 0.9746 - val_loss: 0.1186\n",
      "Epoch 170/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9741 - loss: 0.1147 - val_accuracy: 0.9759 - val_loss: 0.1115\n",
      "Epoch 171/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9745 - loss: 0.1174 - val_accuracy: 0.9756 - val_loss: 0.1138\n",
      "Epoch 172/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9741 - loss: 0.1146 - val_accuracy: 0.9759 - val_loss: 0.1126\n",
      "Epoch 173/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9751 - loss: 0.1133 - val_accuracy: 0.9763 - val_loss: 0.1125\n",
      "Epoch 174/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9783 - loss: 0.1064 - val_accuracy: 0.9759 - val_loss: 0.1141\n",
      "Epoch 175/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.9732 - loss: 0.1147 - val_accuracy: 0.9759 - val_loss: 0.1146\n",
      "Epoch 176/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9740 - loss: 0.1145 - val_accuracy: 0.9759 - val_loss: 0.1156\n",
      "Epoch 177/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9772 - loss: 0.1010 - val_accuracy: 0.9763 - val_loss: 0.1108\n",
      "Epoch 178/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9758 - loss: 0.1109 - val_accuracy: 0.9759 - val_loss: 0.1139\n",
      "Epoch 179/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9742 - loss: 0.1120 - val_accuracy: 0.9763 - val_loss: 0.1124\n",
      "Epoch 180/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9742 - loss: 0.1106 - val_accuracy: 0.9766 - val_loss: 0.1118\n",
      "Epoch 181/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.9737 - loss: 0.1121 - val_accuracy: 0.9766 - val_loss: 0.1098\n",
      "Epoch 182/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9763 - loss: 0.1011 - val_accuracy: 0.9752 - val_loss: 0.1120\n",
      "Epoch 183/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9752 - loss: 0.1094 - val_accuracy: 0.9756 - val_loss: 0.1090\n",
      "Epoch 184/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.9727 - loss: 0.1119 - val_accuracy: 0.9763 - val_loss: 0.1087\n",
      "Epoch 185/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9756 - loss: 0.1016 - val_accuracy: 0.9759 - val_loss: 0.1098\n",
      "Epoch 186/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.9762 - loss: 0.1091 - val_accuracy: 0.9752 - val_loss: 0.1131\n",
      "Epoch 187/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9741 - loss: 0.1084 - val_accuracy: 0.9759 - val_loss: 0.1151\n",
      "Epoch 188/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9754 - loss: 0.1101 - val_accuracy: 0.9752 - val_loss: 0.1169\n",
      "Epoch 189/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9745 - loss: 0.1110 - val_accuracy: 0.9756 - val_loss: 0.1106\n",
      "Epoch 190/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9768 - loss: 0.1017 - val_accuracy: 0.9756 - val_loss: 0.1126\n",
      "Epoch 191/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9753 - loss: 0.1124 - val_accuracy: 0.9756 - val_loss: 0.1155\n",
      "Epoch 192/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9770 - loss: 0.1019 - val_accuracy: 0.9776 - val_loss: 0.1114\n",
      "Epoch 193/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9767 - loss: 0.1019 - val_accuracy: 0.9752 - val_loss: 0.1136\n",
      "Epoch 194/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9765 - loss: 0.1058 - val_accuracy: 0.9759 - val_loss: 0.1104\n",
      "Epoch 195/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9763 - loss: 0.1017 - val_accuracy: 0.9763 - val_loss: 0.1141\n",
      "Epoch 196/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9745 - loss: 0.1131 - val_accuracy: 0.9763 - val_loss: 0.1085\n",
      "Epoch 197/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9760 - loss: 0.1005 - val_accuracy: 0.9759 - val_loss: 0.1094\n",
      "Epoch 198/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9753 - loss: 0.1084 - val_accuracy: 0.9759 - val_loss: 0.1104\n",
      "Epoch 199/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.9754 - loss: 0.1004 - val_accuracy: 0.9766 - val_loss: 0.1076\n",
      "Epoch 200/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9773 - loss: 0.0979 - val_accuracy: 0.9770 - val_loss: 0.1088\n",
      "Epoch 201/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9739 - loss: 0.1110 - val_accuracy: 0.9752 - val_loss: 0.1134\n",
      "Epoch 202/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9769 - loss: 0.0984 - val_accuracy: 0.9770 - val_loss: 0.1068\n",
      "Epoch 203/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9739 - loss: 0.1187 - val_accuracy: 0.9763 - val_loss: 0.1105\n",
      "Epoch 204/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9781 - loss: 0.1087 - val_accuracy: 0.9776 - val_loss: 0.1106\n",
      "Epoch 205/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9725 - loss: 0.1179 - val_accuracy: 0.9759 - val_loss: 0.1080\n",
      "Epoch 206/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9759 - loss: 0.1054 - val_accuracy: 0.9752 - val_loss: 0.1120\n",
      "Epoch 207/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9736 - loss: 0.1107 - val_accuracy: 0.9763 - val_loss: 0.1076\n",
      "Epoch 208/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9782 - loss: 0.1051 - val_accuracy: 0.9763 - val_loss: 0.1063\n",
      "Epoch 209/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9738 - loss: 0.1080 - val_accuracy: 0.9759 - val_loss: 0.1065\n",
      "Epoch 210/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.9770 - loss: 0.0951 - val_accuracy: 0.9770 - val_loss: 0.1061\n",
      "Epoch 211/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9747 - loss: 0.1062 - val_accuracy: 0.9756 - val_loss: 0.1074\n",
      "Epoch 212/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9754 - loss: 0.1096 - val_accuracy: 0.9783 - val_loss: 0.1076\n",
      "Epoch 213/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9739 - loss: 0.1105 - val_accuracy: 0.9752 - val_loss: 0.1084\n",
      "Epoch 214/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9776 - loss: 0.0992 - val_accuracy: 0.9759 - val_loss: 0.1056\n",
      "Epoch 215/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9755 - loss: 0.1064 - val_accuracy: 0.9776 - val_loss: 0.1061\n",
      "Epoch 216/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9770 - loss: 0.1022 - val_accuracy: 0.9756 - val_loss: 0.1081\n",
      "Epoch 217/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9748 - loss: 0.1010 - val_accuracy: 0.9766 - val_loss: 0.1093\n",
      "Epoch 218/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9755 - loss: 0.1065 - val_accuracy: 0.9776 - val_loss: 0.1058\n",
      "Epoch 219/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9786 - loss: 0.0980 - val_accuracy: 0.9773 - val_loss: 0.1073\n",
      "Epoch 220/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9763 - loss: 0.1112 - val_accuracy: 0.9763 - val_loss: 0.1086\n",
      "Epoch 221/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9774 - loss: 0.0976 - val_accuracy: 0.9776 - val_loss: 0.1067\n",
      "Epoch 222/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9758 - loss: 0.0924 - val_accuracy: 0.9773 - val_loss: 0.1061\n",
      "Epoch 223/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9753 - loss: 0.1074 - val_accuracy: 0.9776 - val_loss: 0.1058\n",
      "Epoch 224/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9801 - loss: 0.0969 - val_accuracy: 0.9759 - val_loss: 0.1075\n",
      "Epoch 225/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9776 - loss: 0.0983 - val_accuracy: 0.9773 - val_loss: 0.1063\n",
      "Epoch 226/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9769 - loss: 0.0934 - val_accuracy: 0.9756 - val_loss: 0.1116\n",
      "Epoch 227/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9761 - loss: 0.1049 - val_accuracy: 0.9770 - val_loss: 0.1064\n",
      "Epoch 228/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9747 - loss: 0.0999 - val_accuracy: 0.9770 - val_loss: 0.1057\n",
      "Epoch 229/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.9770 - loss: 0.1044 - val_accuracy: 0.9776 - val_loss: 0.1056\n",
      "Epoch 230/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9755 - loss: 0.1041 - val_accuracy: 0.9766 - val_loss: 0.1051\n",
      "Epoch 231/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9782 - loss: 0.0956 - val_accuracy: 0.9756 - val_loss: 0.1123\n",
      "Epoch 232/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9767 - loss: 0.1030 - val_accuracy: 0.9773 - val_loss: 0.1047\n",
      "Epoch 233/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9764 - loss: 0.1025 - val_accuracy: 0.9752 - val_loss: 0.1078\n",
      "Epoch 234/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9783 - loss: 0.0985 - val_accuracy: 0.9770 - val_loss: 0.1053\n",
      "Epoch 235/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9752 - loss: 0.1036 - val_accuracy: 0.9759 - val_loss: 0.1054\n",
      "Epoch 236/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9784 - loss: 0.0969 - val_accuracy: 0.9756 - val_loss: 0.1079\n",
      "Epoch 237/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9742 - loss: 0.1082 - val_accuracy: 0.9776 - val_loss: 0.1037\n",
      "Epoch 238/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9786 - loss: 0.0907 - val_accuracy: 0.9752 - val_loss: 0.1109\n",
      "Epoch 239/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.9772 - loss: 0.1037 - val_accuracy: 0.9783 - val_loss: 0.1041\n",
      "Epoch 240/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9750 - loss: 0.1111 - val_accuracy: 0.9776 - val_loss: 0.1032\n",
      "Epoch 241/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9790 - loss: 0.0906 - val_accuracy: 0.9780 - val_loss: 0.1038\n",
      "Epoch 242/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9783 - loss: 0.0978 - val_accuracy: 0.9746 - val_loss: 0.1159\n",
      "Epoch 243/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9746 - loss: 0.1068 - val_accuracy: 0.9783 - val_loss: 0.1031\n",
      "Epoch 244/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.9764 - loss: 0.1014 - val_accuracy: 0.9776 - val_loss: 0.1029\n",
      "Epoch 245/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9770 - loss: 0.0986 - val_accuracy: 0.9780 - val_loss: 0.1030\n",
      "Epoch 246/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9786 - loss: 0.0949 - val_accuracy: 0.9780 - val_loss: 0.1016\n",
      "Epoch 247/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9775 - loss: 0.0942 - val_accuracy: 0.9759 - val_loss: 0.1066\n",
      "Epoch 248/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9773 - loss: 0.1019 - val_accuracy: 0.9780 - val_loss: 0.1038\n",
      "Epoch 249/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9796 - loss: 0.0944 - val_accuracy: 0.9756 - val_loss: 0.1075\n",
      "Epoch 250/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9786 - loss: 0.0968 - val_accuracy: 0.9773 - val_loss: 0.1032\n",
      "Epoch 251/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9786 - loss: 0.1026 - val_accuracy: 0.9790 - val_loss: 0.1016\n",
      "Epoch 252/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9758 - loss: 0.1102 - val_accuracy: 0.9773 - val_loss: 0.1005\n",
      "Epoch 253/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9795 - loss: 0.0929 - val_accuracy: 0.9773 - val_loss: 0.1011\n",
      "Epoch 254/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9770 - loss: 0.0951 - val_accuracy: 0.9780 - val_loss: 0.1028\n",
      "Epoch 255/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9772 - loss: 0.1010 - val_accuracy: 0.9776 - val_loss: 0.1014\n",
      "Epoch 256/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9761 - loss: 0.1003 - val_accuracy: 0.9780 - val_loss: 0.1009\n",
      "Epoch 257/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9761 - loss: 0.1018 - val_accuracy: 0.9776 - val_loss: 0.0996\n",
      "Epoch 258/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9777 - loss: 0.0967 - val_accuracy: 0.9773 - val_loss: 0.1007\n",
      "Epoch 259/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9779 - loss: 0.0959 - val_accuracy: 0.9787 - val_loss: 0.1024\n",
      "Epoch 260/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9750 - loss: 0.1003 - val_accuracy: 0.9756 - val_loss: 0.1086\n",
      "Epoch 261/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9787 - loss: 0.0982 - val_accuracy: 0.9790 - val_loss: 0.1015\n",
      "Epoch 262/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9790 - loss: 0.0938 - val_accuracy: 0.9766 - val_loss: 0.1032\n",
      "Epoch 263/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.9784 - loss: 0.0912 - val_accuracy: 0.9763 - val_loss: 0.1038\n",
      "Epoch 264/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.9791 - loss: 0.0861 - val_accuracy: 0.9776 - val_loss: 0.1031\n",
      "Epoch 265/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9779 - loss: 0.0989 - val_accuracy: 0.9783 - val_loss: 0.0992\n",
      "Epoch 266/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9774 - loss: 0.0952 - val_accuracy: 0.9783 - val_loss: 0.1036\n",
      "Epoch 267/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9792 - loss: 0.0905 - val_accuracy: 0.9783 - val_loss: 0.0980\n",
      "Epoch 268/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9777 - loss: 0.0973 - val_accuracy: 0.9763 - val_loss: 0.1029\n",
      "Epoch 269/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.9776 - loss: 0.0965 - val_accuracy: 0.9783 - val_loss: 0.0990\n",
      "Epoch 270/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9790 - loss: 0.0975 - val_accuracy: 0.9787 - val_loss: 0.1002\n",
      "Epoch 271/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.9793 - loss: 0.0860 - val_accuracy: 0.9783 - val_loss: 0.0997\n",
      "Epoch 272/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9797 - loss: 0.0939 - val_accuracy: 0.9780 - val_loss: 0.0972\n",
      "Epoch 273/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9812 - loss: 0.0883 - val_accuracy: 0.9759 - val_loss: 0.1073\n",
      "Epoch 274/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.9798 - loss: 0.0966 - val_accuracy: 0.9783 - val_loss: 0.0997\n",
      "Epoch 275/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9787 - loss: 0.0938 - val_accuracy: 0.9794 - val_loss: 0.0987\n",
      "Epoch 276/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9799 - loss: 0.0931 - val_accuracy: 0.9766 - val_loss: 0.1045\n",
      "Epoch 277/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9771 - loss: 0.0987 - val_accuracy: 0.9780 - val_loss: 0.0993\n",
      "Epoch 278/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9779 - loss: 0.0976 - val_accuracy: 0.9783 - val_loss: 0.0991\n",
      "Epoch 279/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9782 - loss: 0.0890 - val_accuracy: 0.9790 - val_loss: 0.0971\n",
      "Epoch 280/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9774 - loss: 0.0985 - val_accuracy: 0.9783 - val_loss: 0.0976\n",
      "Epoch 281/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.9799 - loss: 0.0893 - val_accuracy: 0.9780 - val_loss: 0.1002\n",
      "Epoch 282/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9786 - loss: 0.0946 - val_accuracy: 0.9783 - val_loss: 0.0971\n",
      "Epoch 283/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9803 - loss: 0.0860 - val_accuracy: 0.9783 - val_loss: 0.0989\n",
      "Epoch 284/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9787 - loss: 0.0945 - val_accuracy: 0.9783 - val_loss: 0.0976\n",
      "Epoch 285/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9795 - loss: 0.0844 - val_accuracy: 0.9783 - val_loss: 0.0974\n",
      "Epoch 286/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9798 - loss: 0.0868 - val_accuracy: 0.9794 - val_loss: 0.0956\n",
      "Epoch 287/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9789 - loss: 0.0914 - val_accuracy: 0.9787 - val_loss: 0.0963\n",
      "Epoch 288/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9799 - loss: 0.0862 - val_accuracy: 0.9787 - val_loss: 0.0968\n",
      "Epoch 289/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9804 - loss: 0.0885 - val_accuracy: 0.9783 - val_loss: 0.0973\n",
      "Epoch 290/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9820 - loss: 0.0785 - val_accuracy: 0.9794 - val_loss: 0.0969\n",
      "Epoch 291/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.9787 - loss: 0.0970 - val_accuracy: 0.9780 - val_loss: 0.0961\n",
      "Epoch 292/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9789 - loss: 0.0950 - val_accuracy: 0.9790 - val_loss: 0.0974\n",
      "Epoch 293/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9785 - loss: 0.0990 - val_accuracy: 0.9794 - val_loss: 0.0959\n",
      "Epoch 294/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.9790 - loss: 0.0918 - val_accuracy: 0.9776 - val_loss: 0.0980\n",
      "Epoch 295/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9804 - loss: 0.0854 - val_accuracy: 0.9770 - val_loss: 0.1029\n",
      "Epoch 296/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9794 - loss: 0.0883 - val_accuracy: 0.9770 - val_loss: 0.1027\n",
      "Epoch 297/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9806 - loss: 0.0880 - val_accuracy: 0.9770 - val_loss: 0.1009\n",
      "Epoch 298/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9787 - loss: 0.0968 - val_accuracy: 0.9790 - val_loss: 0.0987\n",
      "Epoch 299/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9797 - loss: 0.0875 - val_accuracy: 0.9804 - val_loss: 0.0981\n",
      "Epoch 300/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9802 - loss: 0.0848 - val_accuracy: 0.9804 - val_loss: 0.0963\n",
      "Epoch 301/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9796 - loss: 0.0988 - val_accuracy: 0.9780 - val_loss: 0.0991\n",
      "Epoch 302/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9795 - loss: 0.0901 - val_accuracy: 0.9797 - val_loss: 0.0946\n",
      "Epoch 303/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.9808 - loss: 0.0849 - val_accuracy: 0.9773 - val_loss: 0.0994\n",
      "Epoch 304/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9778 - loss: 0.0917 - val_accuracy: 0.9797 - val_loss: 0.0962\n",
      "Epoch 305/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9790 - loss: 0.0925 - val_accuracy: 0.9783 - val_loss: 0.0968\n",
      "Epoch 306/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9777 - loss: 0.0960 - val_accuracy: 0.9773 - val_loss: 0.1010\n",
      "Epoch 307/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9782 - loss: 0.0895 - val_accuracy: 0.9783 - val_loss: 0.0966\n",
      "Epoch 308/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9790 - loss: 0.0922 - val_accuracy: 0.9773 - val_loss: 0.0996\n",
      "Epoch 309/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9806 - loss: 0.0912 - val_accuracy: 0.9763 - val_loss: 0.1112\n",
      "Epoch 310/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9800 - loss: 0.0941 - val_accuracy: 0.9783 - val_loss: 0.0965\n",
      "Epoch 311/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9790 - loss: 0.0932 - val_accuracy: 0.9794 - val_loss: 0.0949\n",
      "Epoch 312/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9789 - loss: 0.0974 - val_accuracy: 0.9790 - val_loss: 0.0938\n",
      "Epoch 313/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9818 - loss: 0.0921 - val_accuracy: 0.9790 - val_loss: 0.0924\n",
      "Epoch 314/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9791 - loss: 0.0896 - val_accuracy: 0.9804 - val_loss: 0.0937\n",
      "Epoch 315/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9793 - loss: 0.0928 - val_accuracy: 0.9780 - val_loss: 0.0978\n",
      "Epoch 316/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9814 - loss: 0.0859 - val_accuracy: 0.9773 - val_loss: 0.1006\n",
      "Epoch 317/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.9803 - loss: 0.0890 - val_accuracy: 0.9780 - val_loss: 0.0974\n",
      "Epoch 318/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9801 - loss: 0.0847 - val_accuracy: 0.9776 - val_loss: 0.0979\n",
      "Epoch 319/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9787 - loss: 0.0893 - val_accuracy: 0.9787 - val_loss: 0.0956\n",
      "Epoch 320/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9790 - loss: 0.0996 - val_accuracy: 0.9790 - val_loss: 0.0943\n",
      "Epoch 321/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9799 - loss: 0.0838 - val_accuracy: 0.9794 - val_loss: 0.0959\n",
      "Epoch 322/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9782 - loss: 0.0968 - val_accuracy: 0.9780 - val_loss: 0.0948\n",
      "Epoch 323/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9826 - loss: 0.0829 - val_accuracy: 0.9804 - val_loss: 0.0920\n",
      "Epoch 324/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9803 - loss: 0.0878 - val_accuracy: 0.9807 - val_loss: 0.0918\n",
      "Epoch 325/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9800 - loss: 0.0891 - val_accuracy: 0.9794 - val_loss: 0.0925\n",
      "Epoch 326/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.9788 - loss: 0.0910 - val_accuracy: 0.9801 - val_loss: 0.0904\n",
      "Epoch 327/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9797 - loss: 0.0825 - val_accuracy: 0.9804 - val_loss: 0.0925\n",
      "Epoch 328/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9790 - loss: 0.0841 - val_accuracy: 0.9797 - val_loss: 0.0926\n",
      "Epoch 329/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.9816 - loss: 0.0817 - val_accuracy: 0.9797 - val_loss: 0.0929\n",
      "Epoch 330/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9783 - loss: 0.0874 - val_accuracy: 0.9773 - val_loss: 0.0961\n",
      "Epoch 331/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9792 - loss: 0.0873 - val_accuracy: 0.9804 - val_loss: 0.0907\n",
      "Epoch 332/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9800 - loss: 0.0850 - val_accuracy: 0.9804 - val_loss: 0.0918\n",
      "Epoch 333/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9784 - loss: 0.0904 - val_accuracy: 0.9797 - val_loss: 0.0930\n",
      "Epoch 334/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9812 - loss: 0.0848 - val_accuracy: 0.9790 - val_loss: 0.0943\n",
      "Epoch 335/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9812 - loss: 0.0839 - val_accuracy: 0.9797 - val_loss: 0.0948\n",
      "Epoch 336/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.9798 - loss: 0.0952 - val_accuracy: 0.9804 - val_loss: 0.0930\n",
      "Epoch 337/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9814 - loss: 0.0796 - val_accuracy: 0.9770 - val_loss: 0.1002\n",
      "Epoch 338/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9819 - loss: 0.0785 - val_accuracy: 0.9814 - val_loss: 0.0934\n",
      "Epoch 339/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9785 - loss: 0.0948 - val_accuracy: 0.9773 - val_loss: 0.0958\n",
      "Epoch 340/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9811 - loss: 0.0816 - val_accuracy: 0.9794 - val_loss: 0.0915\n",
      "Epoch 341/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9798 - loss: 0.0886 - val_accuracy: 0.9811 - val_loss: 0.0900\n",
      "Epoch 342/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9804 - loss: 0.0840 - val_accuracy: 0.9811 - val_loss: 0.0931\n",
      "Epoch 343/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9808 - loss: 0.0949 - val_accuracy: 0.9804 - val_loss: 0.0901\n",
      "Epoch 344/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9818 - loss: 0.0872 - val_accuracy: 0.9804 - val_loss: 0.0905\n",
      "Epoch 345/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9788 - loss: 0.0860 - val_accuracy: 0.9797 - val_loss: 0.0920\n",
      "Epoch 346/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9839 - loss: 0.0744 - val_accuracy: 0.9807 - val_loss: 0.0901\n",
      "Epoch 347/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.9817 - loss: 0.0754 - val_accuracy: 0.9794 - val_loss: 0.0919\n",
      "Epoch 348/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9808 - loss: 0.0839 - val_accuracy: 0.9787 - val_loss: 0.0948\n",
      "Epoch 349/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9819 - loss: 0.0788 - val_accuracy: 0.9804 - val_loss: 0.0914\n",
      "Epoch 350/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9801 - loss: 0.0786 - val_accuracy: 0.9818 - val_loss: 0.0957\n",
      "Epoch 351/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9816 - loss: 0.0858 - val_accuracy: 0.9783 - val_loss: 0.0900\n",
      "Epoch 352/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9823 - loss: 0.0741 - val_accuracy: 0.9807 - val_loss: 0.0914\n",
      "Epoch 353/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9810 - loss: 0.0871 - val_accuracy: 0.9794 - val_loss: 0.0930\n",
      "Epoch 354/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9811 - loss: 0.0942 - val_accuracy: 0.9804 - val_loss: 0.0919\n",
      "Epoch 355/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9827 - loss: 0.0772 - val_accuracy: 0.9804 - val_loss: 0.0899\n",
      "Epoch 356/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9800 - loss: 0.0853 - val_accuracy: 0.9783 - val_loss: 0.0933\n",
      "Epoch 357/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9815 - loss: 0.0881 - val_accuracy: 0.9794 - val_loss: 0.0896\n",
      "Epoch 358/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9838 - loss: 0.0725 - val_accuracy: 0.9797 - val_loss: 0.0947\n",
      "Epoch 359/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9805 - loss: 0.0848 - val_accuracy: 0.9790 - val_loss: 0.0931\n",
      "Epoch 360/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9826 - loss: 0.0787 - val_accuracy: 0.9811 - val_loss: 0.0904\n",
      "Epoch 361/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9818 - loss: 0.0759 - val_accuracy: 0.9776 - val_loss: 0.0975\n",
      "Epoch 362/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9833 - loss: 0.0834 - val_accuracy: 0.9807 - val_loss: 0.0902\n",
      "Epoch 363/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9792 - loss: 0.0796 - val_accuracy: 0.9811 - val_loss: 0.0883\n",
      "Epoch 364/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9799 - loss: 0.0844 - val_accuracy: 0.9818 - val_loss: 0.0873\n",
      "Epoch 365/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.9822 - loss: 0.0802 - val_accuracy: 0.9818 - val_loss: 0.0884\n",
      "Epoch 366/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9825 - loss: 0.0797 - val_accuracy: 0.9814 - val_loss: 0.0874\n",
      "Epoch 367/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9815 - loss: 0.0819 - val_accuracy: 0.9811 - val_loss: 0.0872\n",
      "Epoch 368/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9816 - loss: 0.0781 - val_accuracy: 0.9814 - val_loss: 0.0854\n",
      "Epoch 369/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.9809 - loss: 0.0763 - val_accuracy: 0.9818 - val_loss: 0.0875\n",
      "Epoch 370/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9813 - loss: 0.0811 - val_accuracy: 0.9807 - val_loss: 0.0884\n",
      "Epoch 371/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9814 - loss: 0.0797 - val_accuracy: 0.9818 - val_loss: 0.0859\n",
      "Epoch 372/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9810 - loss: 0.0802 - val_accuracy: 0.9804 - val_loss: 0.0915\n",
      "Epoch 373/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9837 - loss: 0.0719 - val_accuracy: 0.9804 - val_loss: 0.0903\n",
      "Epoch 374/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9821 - loss: 0.0803 - val_accuracy: 0.9814 - val_loss: 0.0868\n",
      "Epoch 375/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9810 - loss: 0.0822 - val_accuracy: 0.9807 - val_loss: 0.0894\n",
      "Epoch 376/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9827 - loss: 0.0818 - val_accuracy: 0.9811 - val_loss: 0.0878\n",
      "Epoch 377/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9837 - loss: 0.0711 - val_accuracy: 0.9794 - val_loss: 0.0917\n",
      "Epoch 378/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.9827 - loss: 0.0800 - val_accuracy: 0.9818 - val_loss: 0.0884\n",
      "Epoch 379/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.9790 - loss: 0.0879 - val_accuracy: 0.9821 - val_loss: 0.0858\n",
      "Epoch 380/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9830 - loss: 0.0763 - val_accuracy: 0.9807 - val_loss: 0.0870\n",
      "Epoch 381/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9797 - loss: 0.0822 - val_accuracy: 0.9814 - val_loss: 0.0872\n",
      "Epoch 382/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9818 - loss: 0.0830 - val_accuracy: 0.9818 - val_loss: 0.0847\n",
      "Epoch 383/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9814 - loss: 0.0835 - val_accuracy: 0.9821 - val_loss: 0.0848\n",
      "Epoch 384/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9833 - loss: 0.0843 - val_accuracy: 0.9818 - val_loss: 0.0874\n",
      "Epoch 385/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9819 - loss: 0.0896 - val_accuracy: 0.9807 - val_loss: 0.0867\n",
      "Epoch 386/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9831 - loss: 0.0782 - val_accuracy: 0.9818 - val_loss: 0.0863\n",
      "Epoch 387/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9829 - loss: 0.0799 - val_accuracy: 0.9818 - val_loss: 0.0861\n",
      "Epoch 388/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9803 - loss: 0.0881 - val_accuracy: 0.9814 - val_loss: 0.0861\n",
      "Epoch 389/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9813 - loss: 0.0785 - val_accuracy: 0.9811 - val_loss: 0.0859\n",
      "Epoch 390/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9797 - loss: 0.0831 - val_accuracy: 0.9801 - val_loss: 0.0868\n",
      "Epoch 391/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9820 - loss: 0.0769 - val_accuracy: 0.9825 - val_loss: 0.0842\n",
      "Epoch 392/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9842 - loss: 0.0732 - val_accuracy: 0.9797 - val_loss: 0.0894\n",
      "Epoch 393/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9834 - loss: 0.0743 - val_accuracy: 0.9821 - val_loss: 0.0848\n",
      "Epoch 394/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9810 - loss: 0.0764 - val_accuracy: 0.9818 - val_loss: 0.0860\n",
      "Epoch 395/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9816 - loss: 0.0798 - val_accuracy: 0.9807 - val_loss: 0.0870\n",
      "Epoch 396/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9825 - loss: 0.0820 - val_accuracy: 0.9814 - val_loss: 0.0853\n",
      "Epoch 397/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9849 - loss: 0.0677 - val_accuracy: 0.9814 - val_loss: 0.0849\n",
      "Epoch 398/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.9824 - loss: 0.0750 - val_accuracy: 0.9818 - val_loss: 0.0852\n",
      "Epoch 399/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9815 - loss: 0.0759 - val_accuracy: 0.9794 - val_loss: 0.0914\n",
      "Epoch 400/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9816 - loss: 0.0744 - val_accuracy: 0.9818 - val_loss: 0.0862\n",
      "Epoch 401/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9802 - loss: 0.0847 - val_accuracy: 0.9801 - val_loss: 0.0895\n",
      "Epoch 402/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9808 - loss: 0.0804 - val_accuracy: 0.9818 - val_loss: 0.0853\n",
      "Epoch 403/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9807 - loss: 0.0847 - val_accuracy: 0.9814 - val_loss: 0.0860\n",
      "Epoch 404/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9825 - loss: 0.0774 - val_accuracy: 0.9825 - val_loss: 0.0851\n",
      "Epoch 405/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9838 - loss: 0.0757 - val_accuracy: 0.9821 - val_loss: 0.0844\n",
      "Epoch 406/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9848 - loss: 0.0669 - val_accuracy: 0.9828 - val_loss: 0.0870\n",
      "Epoch 407/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9803 - loss: 0.0815 - val_accuracy: 0.9801 - val_loss: 0.0884\n",
      "Epoch 408/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9838 - loss: 0.0777 - val_accuracy: 0.9811 - val_loss: 0.0873\n",
      "Epoch 409/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9797 - loss: 0.0875 - val_accuracy: 0.9818 - val_loss: 0.0844\n",
      "Epoch 410/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9827 - loss: 0.0825 - val_accuracy: 0.9801 - val_loss: 0.0908\n",
      "Epoch 411/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9847 - loss: 0.0725 - val_accuracy: 0.9811 - val_loss: 0.0838\n",
      "Epoch 412/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9825 - loss: 0.0801 - val_accuracy: 0.9828 - val_loss: 0.0834\n",
      "Epoch 413/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9814 - loss: 0.0846 - val_accuracy: 0.9825 - val_loss: 0.0858\n",
      "Epoch 414/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9816 - loss: 0.0727 - val_accuracy: 0.9825 - val_loss: 0.0836\n",
      "Epoch 415/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9841 - loss: 0.0707 - val_accuracy: 0.9818 - val_loss: 0.0823\n",
      "Epoch 416/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9835 - loss: 0.0697 - val_accuracy: 0.9821 - val_loss: 0.0847\n",
      "Epoch 417/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9809 - loss: 0.0796 - val_accuracy: 0.9821 - val_loss: 0.0844\n",
      "Epoch 418/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9818 - loss: 0.0793 - val_accuracy: 0.9825 - val_loss: 0.0839\n",
      "Epoch 419/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9806 - loss: 0.0812 - val_accuracy: 0.9814 - val_loss: 0.0832\n",
      "Epoch 420/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9832 - loss: 0.0775 - val_accuracy: 0.9821 - val_loss: 0.0829\n",
      "Epoch 421/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9823 - loss: 0.0707 - val_accuracy: 0.9811 - val_loss: 0.0862\n",
      "Epoch 422/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9841 - loss: 0.0715 - val_accuracy: 0.9835 - val_loss: 0.0857\n",
      "Epoch 423/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9834 - loss: 0.0717 - val_accuracy: 0.9821 - val_loss: 0.0829\n",
      "Epoch 424/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.9800 - loss: 0.0794 - val_accuracy: 0.9818 - val_loss: 0.0824\n",
      "Epoch 425/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9837 - loss: 0.0743 - val_accuracy: 0.9807 - val_loss: 0.0872\n",
      "Epoch 426/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9816 - loss: 0.0818 - val_accuracy: 0.9807 - val_loss: 0.0851\n",
      "Epoch 427/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.9838 - loss: 0.0729 - val_accuracy: 0.9828 - val_loss: 0.0821\n",
      "Epoch 428/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9814 - loss: 0.0847 - val_accuracy: 0.9818 - val_loss: 0.0836\n",
      "Epoch 429/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9821 - loss: 0.0712 - val_accuracy: 0.9811 - val_loss: 0.0845\n",
      "Epoch 430/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9817 - loss: 0.0741 - val_accuracy: 0.9828 - val_loss: 0.0862\n",
      "Epoch 431/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9811 - loss: 0.0679 - val_accuracy: 0.9821 - val_loss: 0.0825\n",
      "Epoch 432/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9818 - loss: 0.0814 - val_accuracy: 0.9821 - val_loss: 0.0836\n",
      "Epoch 433/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9856 - loss: 0.0700 - val_accuracy: 0.9835 - val_loss: 0.0865\n",
      "Epoch 434/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9829 - loss: 0.0692 - val_accuracy: 0.9828 - val_loss: 0.0823\n",
      "Epoch 435/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9841 - loss: 0.0638 - val_accuracy: 0.9787 - val_loss: 0.0940\n",
      "Epoch 436/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9833 - loss: 0.0712 - val_accuracy: 0.9814 - val_loss: 0.0855\n",
      "Epoch 437/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9810 - loss: 0.0793 - val_accuracy: 0.9814 - val_loss: 0.0850\n",
      "Epoch 438/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.9806 - loss: 0.0820 - val_accuracy: 0.9811 - val_loss: 0.0837\n",
      "Epoch 439/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9818 - loss: 0.0743 - val_accuracy: 0.9828 - val_loss: 0.0834\n",
      "Epoch 440/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9829 - loss: 0.0773 - val_accuracy: 0.9825 - val_loss: 0.0828\n",
      "Epoch 441/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9844 - loss: 0.0663 - val_accuracy: 0.9842 - val_loss: 0.0855\n",
      "Epoch 442/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.9814 - loss: 0.0789 - val_accuracy: 0.9828 - val_loss: 0.0815\n",
      "Epoch 443/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9841 - loss: 0.0701 - val_accuracy: 0.9814 - val_loss: 0.0822\n",
      "Epoch 444/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9823 - loss: 0.0795 - val_accuracy: 0.9818 - val_loss: 0.0852\n",
      "Epoch 445/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9835 - loss: 0.0719 - val_accuracy: 0.9807 - val_loss: 0.0882\n",
      "Epoch 446/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9861 - loss: 0.0634 - val_accuracy: 0.9801 - val_loss: 0.0878\n",
      "Epoch 447/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9832 - loss: 0.0682 - val_accuracy: 0.9807 - val_loss: 0.0834\n",
      "Epoch 448/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9846 - loss: 0.0767 - val_accuracy: 0.9797 - val_loss: 0.0897\n",
      "Epoch 449/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9837 - loss: 0.0707 - val_accuracy: 0.9828 - val_loss: 0.0801\n",
      "Epoch 450/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.9806 - loss: 0.0790 - val_accuracy: 0.9831 - val_loss: 0.0818\n",
      "Epoch 451/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9834 - loss: 0.0752 - val_accuracy: 0.9804 - val_loss: 0.0863\n",
      "Epoch 452/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9833 - loss: 0.0758 - val_accuracy: 0.9818 - val_loss: 0.0828\n",
      "Epoch 453/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.9829 - loss: 0.0728 - val_accuracy: 0.9804 - val_loss: 0.0877\n",
      "Epoch 454/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9821 - loss: 0.0813 - val_accuracy: 0.9821 - val_loss: 0.0804\n",
      "Epoch 455/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9832 - loss: 0.0750 - val_accuracy: 0.9818 - val_loss: 0.0821\n",
      "Epoch 456/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.9819 - loss: 0.0773 - val_accuracy: 0.9818 - val_loss: 0.0818\n",
      "Epoch 457/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9822 - loss: 0.0690 - val_accuracy: 0.9821 - val_loss: 0.0805\n",
      "Epoch 458/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9838 - loss: 0.0738 - val_accuracy: 0.9828 - val_loss: 0.0795\n",
      "Epoch 459/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9850 - loss: 0.0669 - val_accuracy: 0.9818 - val_loss: 0.0826\n",
      "Epoch 460/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9840 - loss: 0.0680 - val_accuracy: 0.9818 - val_loss: 0.0830\n",
      "Epoch 461/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9835 - loss: 0.0738 - val_accuracy: 0.9821 - val_loss: 0.0809\n",
      "Epoch 462/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9827 - loss: 0.0689 - val_accuracy: 0.9835 - val_loss: 0.0816\n",
      "Epoch 463/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9835 - loss: 0.0680 - val_accuracy: 0.9811 - val_loss: 0.0834\n",
      "Epoch 464/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9832 - loss: 0.0695 - val_accuracy: 0.9825 - val_loss: 0.0816\n",
      "Epoch 465/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9851 - loss: 0.0735 - val_accuracy: 0.9811 - val_loss: 0.0864\n",
      "Epoch 466/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9802 - loss: 0.0795 - val_accuracy: 0.9828 - val_loss: 0.0801\n",
      "Epoch 467/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9824 - loss: 0.0737 - val_accuracy: 0.9828 - val_loss: 0.0802\n",
      "Epoch 468/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9825 - loss: 0.0718 - val_accuracy: 0.9828 - val_loss: 0.0834\n",
      "Epoch 469/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9837 - loss: 0.0696 - val_accuracy: 0.9807 - val_loss: 0.0855\n",
      "Epoch 470/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9829 - loss: 0.0708 - val_accuracy: 0.9811 - val_loss: 0.0826\n",
      "Epoch 471/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9840 - loss: 0.0691 - val_accuracy: 0.9801 - val_loss: 0.0869\n",
      "Epoch 472/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9839 - loss: 0.0683 - val_accuracy: 0.9814 - val_loss: 0.0837\n",
      "Epoch 473/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9842 - loss: 0.0702 - val_accuracy: 0.9821 - val_loss: 0.0818\n",
      "Epoch 474/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9825 - loss: 0.0785 - val_accuracy: 0.9807 - val_loss: 0.0846\n",
      "Epoch 475/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9861 - loss: 0.0622 - val_accuracy: 0.9818 - val_loss: 0.0815\n",
      "Epoch 476/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9840 - loss: 0.0681 - val_accuracy: 0.9828 - val_loss: 0.0784\n",
      "Epoch 477/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9840 - loss: 0.0772 - val_accuracy: 0.9825 - val_loss: 0.0810\n",
      "Epoch 478/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9848 - loss: 0.0615 - val_accuracy: 0.9835 - val_loss: 0.0857\n",
      "Epoch 479/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9841 - loss: 0.0666 - val_accuracy: 0.9821 - val_loss: 0.0809\n",
      "Epoch 480/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9835 - loss: 0.0629 - val_accuracy: 0.9811 - val_loss: 0.0856\n",
      "Epoch 481/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9838 - loss: 0.0667 - val_accuracy: 0.9821 - val_loss: 0.0794\n",
      "Epoch 482/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9840 - loss: 0.0692 - val_accuracy: 0.9814 - val_loss: 0.0826\n",
      "Epoch 483/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9835 - loss: 0.0688 - val_accuracy: 0.9825 - val_loss: 0.0804\n",
      "Epoch 484/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9847 - loss: 0.0639 - val_accuracy: 0.9814 - val_loss: 0.0808\n",
      "Epoch 485/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9843 - loss: 0.0686 - val_accuracy: 0.9825 - val_loss: 0.0803\n",
      "Epoch 486/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9850 - loss: 0.0711 - val_accuracy: 0.9814 - val_loss: 0.0832\n",
      "Epoch 487/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9831 - loss: 0.0744 - val_accuracy: 0.9807 - val_loss: 0.0900\n",
      "Epoch 488/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9841 - loss: 0.0627 - val_accuracy: 0.9818 - val_loss: 0.0813\n",
      "Epoch 489/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9830 - loss: 0.0815 - val_accuracy: 0.9828 - val_loss: 0.0794\n",
      "Epoch 490/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9839 - loss: 0.0715 - val_accuracy: 0.9821 - val_loss: 0.0811\n",
      "Epoch 491/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9840 - loss: 0.0697 - val_accuracy: 0.9831 - val_loss: 0.0782\n",
      "Epoch 492/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9830 - loss: 0.0782 - val_accuracy: 0.9835 - val_loss: 0.0802\n",
      "Epoch 493/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9843 - loss: 0.0685 - val_accuracy: 0.9821 - val_loss: 0.0817\n",
      "Epoch 494/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9840 - loss: 0.0718 - val_accuracy: 0.9825 - val_loss: 0.0791\n",
      "Epoch 495/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9852 - loss: 0.0657 - val_accuracy: 0.9825 - val_loss: 0.0800\n",
      "Epoch 496/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9832 - loss: 0.0688 - val_accuracy: 0.9825 - val_loss: 0.0817\n",
      "Epoch 497/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9828 - loss: 0.0678 - val_accuracy: 0.9807 - val_loss: 0.0859\n",
      "Epoch 498/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.9848 - loss: 0.0647 - val_accuracy: 0.9821 - val_loss: 0.0807\n",
      "Epoch 499/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9828 - loss: 0.0683 - val_accuracy: 0.9831 - val_loss: 0.0792\n",
      "Epoch 500/500\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9833 - loss: 0.0665 - val_accuracy: 0.9831 - val_loss: 0.0801\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo GRU\n",
    "history_gru = model_gru.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db029f-4a19-4ad0-8f5d-740a8a472321",
   "metadata": {},
   "source": [
    "### Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3bcbf2e-7dd0-404f-ad1e-d6166888f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m18,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,051</span> (70.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,051\u001b[0m (70.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,051</span> (70.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,051\u001b[0m (70.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir o modelo LSTM\n",
    "model_lstm = Sequential()  # Cria um modelo sequencial para o LSTM\n",
    "\n",
    "# Camada LSTM\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))  \n",
    "# Adiciona uma camada LSTM com 50 unidades. A forma de entrada é (n timesteps, n características)\n",
    "\n",
    "model_lstm.add(Dropout(0.2))  \n",
    "# Adiciona uma camada Dropout para prevenir overfitting, desativando aleatoriamente 20% dos neurônios durante o treinamento\n",
    "\n",
    "# Camada de saída\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))  \n",
    "# Adiciona uma camada densa de saída com 1 neurônio e ativação sigmoide para uma tarefa de classificação binária\n",
    "\n",
    "# Compilar o modelo\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "# Compila o modelo usando o otimizador Adam com taxa de aprendizado de 0.001, a função de perda de entropia cruzada binária e a métrica de acurácia\n",
    "\n",
    "# Resumo do modelo\n",
    "model_lstm.summary()  # Exibe um resumo da arquitetura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c05eafc9-416c-49fe-bd21-b6e86a903588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5547 - loss: 0.6899 - val_accuracy: 0.6510 - val_loss: 0.6707\n",
      "Epoch 2/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.6322 - loss: 0.6657 - val_accuracy: 0.6802 - val_loss: 0.6243\n",
      "Epoch 3/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.6767 - loss: 0.6251 - val_accuracy: 0.7084 - val_loss: 0.5899\n",
      "Epoch 4/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7076 - loss: 0.5952 - val_accuracy: 0.7703 - val_loss: 0.5462\n",
      "Epoch 5/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7751 - loss: 0.5481 - val_accuracy: 0.8380 - val_loss: 0.4936\n",
      "Epoch 6/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.8265 - loss: 0.4988 - val_accuracy: 0.8948 - val_loss: 0.4329\n",
      "Epoch 7/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.8776 - loss: 0.4405 - val_accuracy: 0.9264 - val_loss: 0.3723\n",
      "Epoch 8/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9157 - loss: 0.3787 - val_accuracy: 0.9512 - val_loss: 0.3194\n",
      "Epoch 9/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9394 - loss: 0.3221 - val_accuracy: 0.9587 - val_loss: 0.2747\n",
      "Epoch 10/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9518 - loss: 0.2830 - val_accuracy: 0.9591 - val_loss: 0.2402\n",
      "Epoch 11/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9533 - loss: 0.2556 - val_accuracy: 0.9649 - val_loss: 0.2202\n",
      "Epoch 12/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.9583 - loss: 0.2333 - val_accuracy: 0.9642 - val_loss: 0.2007\n",
      "Epoch 13/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.9588 - loss: 0.2154 - val_accuracy: 0.9670 - val_loss: 0.1844\n",
      "Epoch 14/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9596 - loss: 0.2026 - val_accuracy: 0.9642 - val_loss: 0.1748\n",
      "Epoch 15/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.9619 - loss: 0.1969 - val_accuracy: 0.9666 - val_loss: 0.1662\n",
      "Epoch 16/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9600 - loss: 0.1901 - val_accuracy: 0.9670 - val_loss: 0.1645\n",
      "Epoch 17/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.9590 - loss: 0.1836 - val_accuracy: 0.9663 - val_loss: 0.1594\n",
      "Epoch 18/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9626 - loss: 0.1854 - val_accuracy: 0.9673 - val_loss: 0.1566\n",
      "Epoch 19/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.9602 - loss: 0.1830 - val_accuracy: 0.9677 - val_loss: 0.1541\n",
      "Epoch 20/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9594 - loss: 0.1753 - val_accuracy: 0.9660 - val_loss: 0.1565\n",
      "Epoch 21/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.9600 - loss: 0.1733 - val_accuracy: 0.9670 - val_loss: 0.1488\n",
      "Epoch 22/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9596 - loss: 0.1743 - val_accuracy: 0.9660 - val_loss: 0.1555\n",
      "Epoch 23/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9580 - loss: 0.1755 - val_accuracy: 0.9680 - val_loss: 0.1483\n",
      "Epoch 24/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9649 - loss: 0.1616 - val_accuracy: 0.9677 - val_loss: 0.1500\n",
      "Epoch 25/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9591 - loss: 0.1805 - val_accuracy: 0.9670 - val_loss: 0.1479\n",
      "Epoch 26/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9636 - loss: 0.1620 - val_accuracy: 0.9663 - val_loss: 0.1472\n",
      "Epoch 27/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9580 - loss: 0.1911 - val_accuracy: 0.9660 - val_loss: 0.1489\n",
      "Epoch 28/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9597 - loss: 0.1866 - val_accuracy: 0.9656 - val_loss: 0.1472\n",
      "Epoch 29/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9618 - loss: 0.1815 - val_accuracy: 0.9666 - val_loss: 0.1467\n",
      "Epoch 30/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9577 - loss: 0.1892 - val_accuracy: 0.9660 - val_loss: 0.1493\n",
      "Epoch 31/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.9632 - loss: 0.1777 - val_accuracy: 0.9656 - val_loss: 0.1459\n",
      "Epoch 32/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9582 - loss: 0.1707 - val_accuracy: 0.9673 - val_loss: 0.1480\n",
      "Epoch 33/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9621 - loss: 0.1790 - val_accuracy: 0.9639 - val_loss: 0.1518\n",
      "Epoch 34/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.9607 - loss: 0.1823 - val_accuracy: 0.9687 - val_loss: 0.1446\n",
      "Epoch 35/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9629 - loss: 0.1665 - val_accuracy: 0.9673 - val_loss: 0.1436\n",
      "Epoch 36/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9616 - loss: 0.1621 - val_accuracy: 0.9656 - val_loss: 0.1503\n",
      "Epoch 37/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.9603 - loss: 0.1719 - val_accuracy: 0.9660 - val_loss: 0.1467\n",
      "Epoch 38/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.9618 - loss: 0.1709 - val_accuracy: 0.9670 - val_loss: 0.1445\n",
      "Epoch 39/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9618 - loss: 0.1677 - val_accuracy: 0.9660 - val_loss: 0.1511\n",
      "Epoch 40/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9634 - loss: 0.1583 - val_accuracy: 0.9680 - val_loss: 0.1432\n",
      "Epoch 41/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9591 - loss: 0.1754 - val_accuracy: 0.9677 - val_loss: 0.1437\n",
      "Epoch 42/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.9617 - loss: 0.1707 - val_accuracy: 0.9673 - val_loss: 0.1438\n",
      "Epoch 43/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9647 - loss: 0.1573 - val_accuracy: 0.9694 - val_loss: 0.1420\n",
      "Epoch 44/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.9631 - loss: 0.1819 - val_accuracy: 0.9663 - val_loss: 0.1505\n",
      "Epoch 45/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.9584 - loss: 0.1660 - val_accuracy: 0.9704 - val_loss: 0.1446\n",
      "Epoch 46/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9610 - loss: 0.1662 - val_accuracy: 0.9684 - val_loss: 0.1423\n",
      "Epoch 47/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9666 - loss: 0.1565 - val_accuracy: 0.9666 - val_loss: 0.1422\n",
      "Epoch 48/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.9629 - loss: 0.1528 - val_accuracy: 0.9673 - val_loss: 0.1405\n",
      "Epoch 49/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9628 - loss: 0.1752 - val_accuracy: 0.9684 - val_loss: 0.1404\n",
      "Epoch 50/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.9615 - loss: 0.1713 - val_accuracy: 0.9687 - val_loss: 0.1395\n",
      "Epoch 51/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9646 - loss: 0.1520 - val_accuracy: 0.9670 - val_loss: 0.1571\n",
      "Epoch 52/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9634 - loss: 0.1704 - val_accuracy: 0.9687 - val_loss: 0.1390\n",
      "Epoch 53/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9634 - loss: 0.1528 - val_accuracy: 0.9697 - val_loss: 0.1382\n",
      "Epoch 54/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.9652 - loss: 0.1481 - val_accuracy: 0.9687 - val_loss: 0.1398\n",
      "Epoch 55/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9614 - loss: 0.1560 - val_accuracy: 0.9687 - val_loss: 0.1392\n",
      "Epoch 56/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.9677 - loss: 0.1432 - val_accuracy: 0.9704 - val_loss: 0.1379\n",
      "Epoch 57/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.9632 - loss: 0.1636 - val_accuracy: 0.9684 - val_loss: 0.1454\n",
      "Epoch 58/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9645 - loss: 0.1552 - val_accuracy: 0.9680 - val_loss: 0.1375\n",
      "Epoch 59/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.9670 - loss: 0.1593 - val_accuracy: 0.9691 - val_loss: 0.1371\n",
      "Epoch 60/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9638 - loss: 0.1544 - val_accuracy: 0.9715 - val_loss: 0.1363\n",
      "Epoch 61/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9631 - loss: 0.1621 - val_accuracy: 0.9701 - val_loss: 0.1373\n",
      "Epoch 62/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.9681 - loss: 0.1495 - val_accuracy: 0.9711 - val_loss: 0.1361\n",
      "Epoch 63/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.9639 - loss: 0.1591 - val_accuracy: 0.9701 - val_loss: 0.1357\n",
      "Epoch 64/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9677 - loss: 0.1440 - val_accuracy: 0.9701 - val_loss: 0.1374\n",
      "Epoch 65/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9666 - loss: 0.1529 - val_accuracy: 0.9697 - val_loss: 0.1409\n",
      "Epoch 66/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9653 - loss: 0.1575 - val_accuracy: 0.9715 - val_loss: 0.1339\n",
      "Epoch 67/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9662 - loss: 0.1473 - val_accuracy: 0.9715 - val_loss: 0.1333\n",
      "Epoch 68/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9678 - loss: 0.1534 - val_accuracy: 0.9708 - val_loss: 0.1382\n",
      "Epoch 69/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - accuracy: 0.9662 - loss: 0.1570 - val_accuracy: 0.9708 - val_loss: 0.1359\n",
      "Epoch 70/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9674 - loss: 0.1499 - val_accuracy: 0.9697 - val_loss: 0.1378\n",
      "Epoch 71/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.9667 - loss: 0.1505 - val_accuracy: 0.9715 - val_loss: 0.1332\n",
      "Epoch 72/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9659 - loss: 0.1484 - val_accuracy: 0.9711 - val_loss: 0.1353\n",
      "Epoch 73/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.9660 - loss: 0.1583 - val_accuracy: 0.9701 - val_loss: 0.1325\n",
      "Epoch 74/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.9685 - loss: 0.1457 - val_accuracy: 0.9701 - val_loss: 0.1394\n",
      "Epoch 75/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9683 - loss: 0.1364 - val_accuracy: 0.9718 - val_loss: 0.1327\n",
      "Epoch 76/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9659 - loss: 0.1437 - val_accuracy: 0.9708 - val_loss: 0.1328\n",
      "Epoch 77/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9681 - loss: 0.1380 - val_accuracy: 0.9721 - val_loss: 0.1309\n",
      "Epoch 78/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.9646 - loss: 0.1596 - val_accuracy: 0.9708 - val_loss: 0.1351\n",
      "Epoch 79/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.9675 - loss: 0.1660 - val_accuracy: 0.9718 - val_loss: 0.1334\n",
      "Epoch 80/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.9685 - loss: 0.1401 - val_accuracy: 0.9718 - val_loss: 0.1327\n",
      "Epoch 81/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9704 - loss: 0.1354 - val_accuracy: 0.9735 - val_loss: 0.1299\n",
      "Epoch 82/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9665 - loss: 0.1493 - val_accuracy: 0.9728 - val_loss: 0.1282\n",
      "Epoch 83/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9693 - loss: 0.1384 - val_accuracy: 0.9728 - val_loss: 0.1295\n",
      "Epoch 84/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.9670 - loss: 0.1481 - val_accuracy: 0.9735 - val_loss: 0.1298\n",
      "Epoch 85/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9688 - loss: 0.1418 - val_accuracy: 0.9728 - val_loss: 0.1289\n",
      "Epoch 86/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9681 - loss: 0.1469 - val_accuracy: 0.9721 - val_loss: 0.1322\n",
      "Epoch 87/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.9680 - loss: 0.1439 - val_accuracy: 0.9732 - val_loss: 0.1295\n",
      "Epoch 88/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.9660 - loss: 0.1529 - val_accuracy: 0.9732 - val_loss: 0.1281\n",
      "Epoch 89/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9699 - loss: 0.1410 - val_accuracy: 0.9728 - val_loss: 0.1302\n",
      "Epoch 90/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9685 - loss: 0.1466 - val_accuracy: 0.9721 - val_loss: 0.1338\n",
      "Epoch 91/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9700 - loss: 0.1478 - val_accuracy: 0.9732 - val_loss: 0.1275\n",
      "Epoch 92/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.9692 - loss: 0.1361 - val_accuracy: 0.9732 - val_loss: 0.1306\n",
      "Epoch 93/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9684 - loss: 0.1561 - val_accuracy: 0.9739 - val_loss: 0.1255\n",
      "Epoch 94/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.9705 - loss: 0.1299 - val_accuracy: 0.9739 - val_loss: 0.1261\n",
      "Epoch 95/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.9683 - loss: 0.1407 - val_accuracy: 0.9735 - val_loss: 0.1266\n",
      "Epoch 96/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9670 - loss: 0.1501 - val_accuracy: 0.9739 - val_loss: 0.1340\n",
      "Epoch 97/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.9730 - loss: 0.1254 - val_accuracy: 0.9718 - val_loss: 0.1361\n",
      "Epoch 98/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9714 - loss: 0.1327 - val_accuracy: 0.9735 - val_loss: 0.1254\n",
      "Epoch 99/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9705 - loss: 0.1527 - val_accuracy: 0.9742 - val_loss: 0.1260\n",
      "Epoch 100/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9671 - loss: 0.1449 - val_accuracy: 0.9739 - val_loss: 0.1236\n",
      "Epoch 101/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9705 - loss: 0.1380 - val_accuracy: 0.9739 - val_loss: 0.1296\n",
      "Epoch 102/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9691 - loss: 0.1369 - val_accuracy: 0.9735 - val_loss: 0.1315\n",
      "Epoch 103/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9696 - loss: 0.1421 - val_accuracy: 0.9742 - val_loss: 0.1240\n",
      "Epoch 104/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.9685 - loss: 0.1431 - val_accuracy: 0.9742 - val_loss: 0.1233\n",
      "Epoch 105/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.9684 - loss: 0.1459 - val_accuracy: 0.9742 - val_loss: 0.1259\n",
      "Epoch 106/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9706 - loss: 0.1352 - val_accuracy: 0.9749 - val_loss: 0.1250\n",
      "Epoch 107/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9734 - loss: 0.1282 - val_accuracy: 0.9742 - val_loss: 0.1250\n",
      "Epoch 108/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9710 - loss: 0.1343 - val_accuracy: 0.9742 - val_loss: 0.1243\n",
      "Epoch 109/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.9695 - loss: 0.1343 - val_accuracy: 0.9742 - val_loss: 0.1228\n",
      "Epoch 110/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - accuracy: 0.9709 - loss: 0.1354 - val_accuracy: 0.9746 - val_loss: 0.1234\n",
      "Epoch 111/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.9705 - loss: 0.1322 - val_accuracy: 0.9739 - val_loss: 0.1241\n",
      "Epoch 112/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9680 - loss: 0.1418 - val_accuracy: 0.9759 - val_loss: 0.1275\n",
      "Epoch 113/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9706 - loss: 0.1354 - val_accuracy: 0.9746 - val_loss: 0.1234\n",
      "Epoch 114/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - accuracy: 0.9687 - loss: 0.1309 - val_accuracy: 0.9742 - val_loss: 0.1228\n",
      "Epoch 115/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9700 - loss: 0.1432 - val_accuracy: 0.9739 - val_loss: 0.1241\n",
      "Epoch 116/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.9697 - loss: 0.1368 - val_accuracy: 0.9746 - val_loss: 0.1215\n",
      "Epoch 117/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9721 - loss: 0.1327 - val_accuracy: 0.9742 - val_loss: 0.1234\n",
      "Epoch 118/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.9711 - loss: 0.1290 - val_accuracy: 0.9752 - val_loss: 0.1232\n",
      "Epoch 119/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.9723 - loss: 0.1297 - val_accuracy: 0.9739 - val_loss: 0.1240\n",
      "Epoch 120/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9731 - loss: 0.1182 - val_accuracy: 0.9660 - val_loss: 0.1465\n",
      "Epoch 121/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9727 - loss: 0.1204 - val_accuracy: 0.9746 - val_loss: 0.1214\n",
      "Epoch 122/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.9712 - loss: 0.1237 - val_accuracy: 0.9739 - val_loss: 0.1268\n",
      "Epoch 123/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9692 - loss: 0.1309 - val_accuracy: 0.9746 - val_loss: 0.1200\n",
      "Epoch 124/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9733 - loss: 0.1214 - val_accuracy: 0.9749 - val_loss: 0.1202\n",
      "Epoch 125/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9717 - loss: 0.1296 - val_accuracy: 0.9742 - val_loss: 0.1211\n",
      "Epoch 126/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.9724 - loss: 0.1259 - val_accuracy: 0.9739 - val_loss: 0.1265\n",
      "Epoch 127/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.9729 - loss: 0.1256 - val_accuracy: 0.9749 - val_loss: 0.1187\n",
      "Epoch 128/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.9708 - loss: 0.1239 - val_accuracy: 0.9749 - val_loss: 0.1187\n",
      "Epoch 129/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.9685 - loss: 0.1400 - val_accuracy: 0.9749 - val_loss: 0.1190\n",
      "Epoch 130/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.9697 - loss: 0.1300 - val_accuracy: 0.9749 - val_loss: 0.1185\n",
      "Epoch 131/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9711 - loss: 0.1265 - val_accuracy: 0.9752 - val_loss: 0.1181\n",
      "Epoch 132/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9750 - loss: 0.1184 - val_accuracy: 0.9752 - val_loss: 0.1184\n",
      "Epoch 133/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.9724 - loss: 0.1225 - val_accuracy: 0.9742 - val_loss: 0.1232\n",
      "Epoch 134/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.9723 - loss: 0.1234 - val_accuracy: 0.9749 - val_loss: 0.1175\n",
      "Epoch 135/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.9730 - loss: 0.1265 - val_accuracy: 0.9759 - val_loss: 0.1171\n",
      "Epoch 136/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.9735 - loss: 0.1202 - val_accuracy: 0.9756 - val_loss: 0.1182\n",
      "Epoch 137/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.9723 - loss: 0.1266 - val_accuracy: 0.9746 - val_loss: 0.1258\n",
      "Epoch 138/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.9732 - loss: 0.1213 - val_accuracy: 0.9752 - val_loss: 0.1174\n",
      "Epoch 139/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.9725 - loss: 0.1267 - val_accuracy: 0.9746 - val_loss: 0.1182\n",
      "Epoch 140/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.9748 - loss: 0.1149 - val_accuracy: 0.9739 - val_loss: 0.1250\n",
      "Epoch 141/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.9740 - loss: 0.1257 - val_accuracy: 0.9752 - val_loss: 0.1188\n",
      "Epoch 142/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - accuracy: 0.9736 - loss: 0.1117 - val_accuracy: 0.9756 - val_loss: 0.1179\n",
      "Epoch 143/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.9722 - loss: 0.1227 - val_accuracy: 0.9763 - val_loss: 0.1183\n",
      "Epoch 144/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.9699 - loss: 0.1338 - val_accuracy: 0.9746 - val_loss: 0.1171\n",
      "Epoch 145/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.9740 - loss: 0.1165 - val_accuracy: 0.9746 - val_loss: 0.1174\n",
      "Epoch 146/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9702 - loss: 0.1257 - val_accuracy: 0.9756 - val_loss: 0.1154\n",
      "Epoch 147/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.9746 - loss: 0.1274 - val_accuracy: 0.9756 - val_loss: 0.1151\n",
      "Epoch 148/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9725 - loss: 0.1225 - val_accuracy: 0.9756 - val_loss: 0.1166\n",
      "Epoch 149/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.9742 - loss: 0.1165 - val_accuracy: 0.9742 - val_loss: 0.1214\n",
      "Epoch 150/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9733 - loss: 0.1295 - val_accuracy: 0.9756 - val_loss: 0.1162\n",
      "Epoch 151/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.9716 - loss: 0.1241 - val_accuracy: 0.9742 - val_loss: 0.1222\n",
      "Epoch 152/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.9729 - loss: 0.1285 - val_accuracy: 0.9749 - val_loss: 0.1170\n",
      "Epoch 153/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.9726 - loss: 0.1197 - val_accuracy: 0.9752 - val_loss: 0.1166\n",
      "Epoch 154/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9730 - loss: 0.1252 - val_accuracy: 0.9752 - val_loss: 0.1163\n",
      "Epoch 155/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.9697 - loss: 0.1235 - val_accuracy: 0.9763 - val_loss: 0.1157\n",
      "Epoch 156/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.9728 - loss: 0.1213 - val_accuracy: 0.9756 - val_loss: 0.1145\n",
      "Epoch 157/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9738 - loss: 0.1132 - val_accuracy: 0.9756 - val_loss: 0.1157\n",
      "Epoch 158/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9745 - loss: 0.1084 - val_accuracy: 0.9752 - val_loss: 0.1158\n",
      "Epoch 159/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9714 - loss: 0.1319 - val_accuracy: 0.9739 - val_loss: 0.1242\n",
      "Epoch 160/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9745 - loss: 0.1121 - val_accuracy: 0.9756 - val_loss: 0.1144\n",
      "Epoch 161/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9708 - loss: 0.1327 - val_accuracy: 0.9752 - val_loss: 0.1139\n",
      "Epoch 162/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9732 - loss: 0.1287 - val_accuracy: 0.9752 - val_loss: 0.1168\n",
      "Epoch 163/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.9724 - loss: 0.1264 - val_accuracy: 0.9759 - val_loss: 0.1135\n",
      "Epoch 164/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.9733 - loss: 0.1284 - val_accuracy: 0.9752 - val_loss: 0.1152\n",
      "Epoch 165/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.9745 - loss: 0.1208 - val_accuracy: 0.9759 - val_loss: 0.1139\n",
      "Epoch 166/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9735 - loss: 0.1111 - val_accuracy: 0.9759 - val_loss: 0.1134\n",
      "Epoch 167/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.9751 - loss: 0.1068 - val_accuracy: 0.9759 - val_loss: 0.1162\n",
      "Epoch 168/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9724 - loss: 0.1315 - val_accuracy: 0.9759 - val_loss: 0.1164\n",
      "Epoch 169/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9737 - loss: 0.1076 - val_accuracy: 0.9746 - val_loss: 0.1187\n",
      "Epoch 170/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9731 - loss: 0.1259 - val_accuracy: 0.9752 - val_loss: 0.1167\n",
      "Epoch 171/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.9746 - loss: 0.1146 - val_accuracy: 0.9746 - val_loss: 0.1146\n",
      "Epoch 172/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9764 - loss: 0.1099 - val_accuracy: 0.9752 - val_loss: 0.1134\n",
      "Epoch 173/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.9719 - loss: 0.1254 - val_accuracy: 0.9759 - val_loss: 0.1139\n",
      "Epoch 174/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.9713 - loss: 0.1249 - val_accuracy: 0.9759 - val_loss: 0.1134\n",
      "Epoch 175/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9754 - loss: 0.1112 - val_accuracy: 0.9759 - val_loss: 0.1148\n",
      "Epoch 176/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.9709 - loss: 0.1080 - val_accuracy: 0.9742 - val_loss: 0.1216\n",
      "Epoch 177/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.9731 - loss: 0.1258 - val_accuracy: 0.9756 - val_loss: 0.1122\n",
      "Epoch 178/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.9741 - loss: 0.1108 - val_accuracy: 0.9759 - val_loss: 0.1162\n",
      "Epoch 179/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.9729 - loss: 0.1146 - val_accuracy: 0.9759 - val_loss: 0.1146\n",
      "Epoch 180/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.9763 - loss: 0.1116 - val_accuracy: 0.9756 - val_loss: 0.1134\n",
      "Epoch 181/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9745 - loss: 0.1079 - val_accuracy: 0.9766 - val_loss: 0.1137\n",
      "Epoch 182/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.9729 - loss: 0.1264 - val_accuracy: 0.9756 - val_loss: 0.1138\n",
      "Epoch 183/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.9742 - loss: 0.1036 - val_accuracy: 0.9766 - val_loss: 0.1121\n",
      "Epoch 184/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.9731 - loss: 0.1173 - val_accuracy: 0.9756 - val_loss: 0.1129\n",
      "Epoch 185/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.9726 - loss: 0.1180 - val_accuracy: 0.9749 - val_loss: 0.1134\n",
      "Epoch 186/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.9760 - loss: 0.1149 - val_accuracy: 0.9763 - val_loss: 0.1155\n",
      "Epoch 187/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.9718 - loss: 0.1245 - val_accuracy: 0.9766 - val_loss: 0.1104\n",
      "Epoch 188/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.9759 - loss: 0.1123 - val_accuracy: 0.9759 - val_loss: 0.1114\n",
      "Epoch 189/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.9739 - loss: 0.1138 - val_accuracy: 0.9766 - val_loss: 0.1123\n",
      "Epoch 190/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9752 - loss: 0.1068 - val_accuracy: 0.9766 - val_loss: 0.1099\n",
      "Epoch 191/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9777 - loss: 0.1038 - val_accuracy: 0.9770 - val_loss: 0.1104\n",
      "Epoch 192/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9739 - loss: 0.1221 - val_accuracy: 0.9759 - val_loss: 0.1133\n",
      "Epoch 193/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9744 - loss: 0.1191 - val_accuracy: 0.9759 - val_loss: 0.1118\n",
      "Epoch 194/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.9735 - loss: 0.1154 - val_accuracy: 0.9759 - val_loss: 0.1104\n",
      "Epoch 195/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.9747 - loss: 0.1148 - val_accuracy: 0.9759 - val_loss: 0.1094\n",
      "Epoch 196/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.9748 - loss: 0.1159 - val_accuracy: 0.9770 - val_loss: 0.1089\n",
      "Epoch 197/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.9756 - loss: 0.1137 - val_accuracy: 0.9759 - val_loss: 0.1103\n",
      "Epoch 198/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9752 - loss: 0.1100 - val_accuracy: 0.9766 - val_loss: 0.1124\n",
      "Epoch 199/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.9751 - loss: 0.1020 - val_accuracy: 0.9766 - val_loss: 0.1098\n",
      "Epoch 200/200\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.9755 - loss: 0.1082 - val_accuracy: 0.9759 - val_loss: 0.1104\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo LSTM\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38966e17-13f4-4b10-b17a-54c1db1630c4",
   "metadata": {},
   "source": [
    "## Avaliando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f15b60-20f0-40c2-a42c-53faf4da7886",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b40bc0c2-f0e2-44c8-a0f6-96fa24e10ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.9820 - loss: 0.0969\n",
      "Test Loss GRU: 0.0934840515255928\n",
      "Test Accuracy GRU: 0.9810230731964111\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98      1823\n",
      "         1.0       0.97      1.00      0.98      1813\n",
      "\n",
      "    accuracy                           0.98      3636\n",
      "   macro avg       0.98      0.98      0.98      3636\n",
      "weighted avg       0.98      0.98      0.98      3636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Converter X_test e y_test para float32\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "y_test = np.array(y_test).astype('float32')\n",
    "\n",
    "# Avaliar o modelo GRU com os dados de teste\n",
    "loss_gru, accuracy_gru = model_gru.evaluate(X_test, y_test)\n",
    "print(f'Test Loss GRU: {loss_gru}')\n",
    "print(f'Test Accuracy GRU: {accuracy_gru}')\n",
    "\n",
    "# Fazer previsões com o modelo GRU\n",
    "y_pred_gru = model_gru.predict(X_test)\n",
    "y_pred_gru = (y_pred_gru > 0.5).astype(int)\n",
    "\n",
    "# Exibir o relatório de classificação\n",
    "print(classification_report(y_test, y_pred_gru))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafc2ab-a9ce-41fb-80fd-f888c785378d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61fd51a9-532b-42a9-b8d9-fe744cc92c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9740 - loss: 0.1446\n",
      "Test Loss LSTM: 0.1315179020166397\n",
      "Test Accuracy LSTM: 0.9757975935935974\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.98      1823\n",
      "         1.0       0.95      1.00      0.98      1813\n",
      "\n",
      "    accuracy                           0.98      3636\n",
      "   macro avg       0.98      0.98      0.98      3636\n",
      "weighted avg       0.98      0.98      0.98      3636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo LSTM com os dados de teste\n",
    "loss_lstm, accuracy_lstm = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test Loss LSTM: {loss_lstm}')\n",
    "print(f'Test Accuracy LSTM: {accuracy_lstm}')\n",
    "\n",
    "# Fazer previsões com o modelo LSTM\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "y_pred_lstm = (y_pred_lstm > 0.5).astype(int)\n",
    "\n",
    "# Exibir o relatório de classificação\n",
    "print(classification_report(y_test, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883bee6-8da3-4f39-8b0e-f96b5379417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7e6af-47e0-4814-9fe1-d5fd72c92b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5faf6-9bc1-41a7-b6cf-745579ef70b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0523b2-db32-4580-b2d8-994a9e0aec38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e7acd-22b5-4c91-9c62-3589fa5cae6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782836e-4c80-4b24-8e44-aaef8039c1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145fa98c-9536-40fc-9984-b74dbca02123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c7142-26a3-49e8-a00d-0107774d47ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcf0f4-07b9-467e-bffb-a543fd08a6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
