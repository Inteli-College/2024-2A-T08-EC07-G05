{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f826d0-2524-4970-8f63-e1e1c881bf32",
   "metadata": {},
   "source": [
    "# Criação, treino e teste do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f76b5-3009-4b77-84f9-560dab31124b",
   "metadata": {},
   "source": [
    "## Instalando bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df2ea2a6-9752-4881-8ecb-ab1b846eccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (1.66.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
      "Requirement already satisfied: namex in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae38060-6475-489d-99d2-e0da38622e69",
   "metadata": {},
   "source": [
    "## Leitura e Verificação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79857831-cd3e-4781-a548-dce9bff84cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEM_FALHA_ROD\n",
      "0.0    64841\n",
      "1.0     4653\n",
      "Name: count, dtype: int64\n",
      "KNR                       0\n",
      "QTD_STATUS_1_OK           0\n",
      "QTD_STATUS_1_NOK          0\n",
      "QTD_STATUS_2_OK           0\n",
      "QTD_STATUS_2_NOK          0\n",
      "QTD_STATUS_718_OK         0\n",
      "QTD_STATUS_718_NOK        0\n",
      "TEMPO_MEDIO               0\n",
      "MOTOR                     0\n",
      "COR                       0\n",
      "QTD_HALLE_                0\n",
      "QTD_HALLE_AGUA            0\n",
      "QTD_HALLE_BUY             0\n",
      "QTD_HALLE_CAB             0\n",
      "QTD_HALLE_DKA             0\n",
      "QTD_HALLE_ESPC            0\n",
      "QTD_HALLE_PROC            0\n",
      "QTD_HALLE_PROF            0\n",
      "QTD_HALLE_PVC             0\n",
      "QTD_HALLE_ROD             0\n",
      "QTD_HALLE_RUID            0\n",
      "QTD_HALLE_TLUI            0\n",
      "QTD_HALLE_ZP5             0\n",
      "QTD_HALLE_ZP5A            0\n",
      "QTD_HALLE_ZP6             0\n",
      "QTD_HALLE_ZP61            0\n",
      "QTD_HALLE_ZP62            0\n",
      "QTD_HALLE_ZP7             0\n",
      "QTD_HALLE_ZP8             0\n",
      "QTD_HALLE_ZP82            0\n",
      "QTD_HALLE_ZP8R            0\n",
      "QTD_SGROUP_#MULTIVALUE    0\n",
      "QTD_SGROUP_-2             0\n",
      "QTD_SGROUP_1              0\n",
      "QTD_SGROUP_133            0\n",
      "QTD_SGROUP_137            0\n",
      "QTD_SGROUP_140            0\n",
      "QTD_SGROUP_2              0\n",
      "QTD_SGROUP_4              0\n",
      "QTD_SGROUP_5              0\n",
      "QTD_SGROUP_9830946        0\n",
      "TEM_FALHA_ROD             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('DF_KNRS_COMUM_PROCESSADO.parquet')\n",
    "print(df['TEM_FALHA_ROD'].value_counts())  # Verificando a distribuição da variável alvo\n",
    "\n",
    "df = df.dropna()  # Removendo valores nulos\n",
    "print(df.isnull().sum())  # Verificando novamente para garantir que não haja valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6230e2-5f04-4982-96b9-6d8b87fd2862",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1534e9fd-0ea5-48c8-b7fa-700076499a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando variáveis dummies\n",
    "df = pd.get_dummies(df, columns=['COR', 'MOTOR'], drop_first=True)\n",
    "\n",
    "# Removendo colunas desnecessárias\n",
    "df = df.drop(columns=[\"KNR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0728d-c613-41c0-86ff-0cbe3cd64412",
   "metadata": {},
   "source": [
    "## Balanceamento das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b5860eb-baaa-40cb-8650-ec93578b031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler  # Importa o método RandomUnderSampler para balanceamento de classes\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)  # Inicializa o RandomUnderSampler com uma semente de aleatoriedade fixa\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)  # Aplica o balanceamento de classes aos dados, retornando as amostras balanceadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e0369-dc35-4611-a33f-420b359864fe",
   "metadata": {},
   "source": [
    "## Dividindo o dataset entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a580506-0e4a-4601-8477-016b0c7d2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Importa a função para dividir os dados em conjuntos de treino e teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  \n",
    "# Divide os dados balanceados em conjuntos de treino (80%) e teste (20%), com uma semente de aleatoriedade fixa para reprodução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384f474-74f4-49e7-9eff-bfb02d435da1",
   "metadata": {},
   "source": [
    "## Redimensionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "696c092c-acb2-4863-9ae2-35b197f871fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))  \n",
    "# Altera a forma de X_train para (n amostras, 1, n características) para compatibilidade com redes neurais que esperam uma dimensão adicional\n",
    "\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))  \n",
    "# Altera a forma de X_test de maneira semelhante\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)  \n",
    "# Converte X_train para um array NumPy com tipo de dado float32\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.float32)  \n",
    "# Converte y_train para um array NumPy com tipo de dado float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2858d-ca75-4d6e-a837-c6f4e781a0ae",
   "metadata": {},
   "source": [
    "## Construção dos Modelos (LSTM e GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b850a-75fc-458a-8270-c7d1669228fb",
   "metadata": {},
   "source": [
    "### Modelo GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4f65e3a-c828-4360-b810-2aa6a274e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizzi26/Documents/Github/faculdade/2024-2A-T08-EC07-G05/src/notebooks/venv/lib64/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential()  # Cria um modelo sequencial, que é uma pilha linear de camadas\n",
    "\n",
    "model_gru.add(GRU(50, input_shape=(X_train.shape[1], X_train.shape[2])))  \n",
    "# Adiciona uma camada GRU com 50 unidades. A forma de entrada é (n timesteps, n características)\n",
    "\n",
    "model_gru.add(Dropout(0.2))  \n",
    "# Adiciona uma camada Dropout para prevenir overfitting, desativando aleatoriamente 20% dos neurônios durante o treinamento\n",
    "\n",
    "model_gru.add(Dense(1, activation='sigmoid'))  \n",
    "# Adiciona uma camada densa de saída com 1 neurônio e ativação sigmoide para uma tarefa de classificação binária\n",
    "\n",
    "model_gru.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "# Compila o modelo usando o otimizador Adam com taxa de aprendizado de 0.001, a função de perda de entropia cruzada binária e a métrica de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f69a1d73-5e39-43cb-934b-d8eb3e4bf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4918 - loss: 0.7550 - val_accuracy: 0.5165 - val_loss: 0.6958\n",
      "Epoch 2/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5055 - loss: 0.7142 - val_accuracy: 0.5075 - val_loss: 0.7000\n",
      "Epoch 3/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5204 - loss: 0.7045 - val_accuracy: 0.5165 - val_loss: 0.6937\n",
      "Epoch 4/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5222 - loss: 0.6967 - val_accuracy: 0.5038 - val_loss: 0.6959\n",
      "Epoch 5/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4952 - loss: 0.7099 - val_accuracy: 0.4895 - val_loss: 0.6983\n",
      "Epoch 6/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5073 - loss: 0.7004 - val_accuracy: 0.5150 - val_loss: 0.6945\n",
      "Epoch 7/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5089 - loss: 0.6992 - val_accuracy: 0.5293 - val_loss: 0.6946\n",
      "Epoch 8/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5332 - loss: 0.6910 - val_accuracy: 0.5616 - val_loss: 0.6897\n",
      "Epoch 9/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5387 - loss: 0.6915 - val_accuracy: 0.6119 - val_loss: 0.6801\n",
      "Epoch 10/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5513 - loss: 0.6844 - val_accuracy: 0.7027 - val_loss: 0.6735\n",
      "Epoch 11/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5962 - loss: 0.6726 - val_accuracy: 0.5450 - val_loss: 0.6623\n",
      "Epoch 12/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5879 - loss: 0.6748 - val_accuracy: 0.7057 - val_loss: 0.6462\n",
      "Epoch 13/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6765 - loss: 0.6411 - val_accuracy: 0.8146 - val_loss: 0.6191\n",
      "Epoch 14/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.6108 - val_accuracy: 0.8544 - val_loss: 0.5862\n",
      "Epoch 15/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7697 - loss: 0.5912 - val_accuracy: 0.7462 - val_loss: 0.5913\n",
      "Epoch 16/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 0.5618 - val_accuracy: 0.9212 - val_loss: 0.5381\n",
      "Epoch 17/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8566 - loss: 0.5321 - val_accuracy: 0.9407 - val_loss: 0.5091\n",
      "Epoch 18/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.5224 - val_accuracy: 0.9287 - val_loss: 0.4968\n",
      "Epoch 19/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8497 - loss: 0.4953 - val_accuracy: 0.9024 - val_loss: 0.4841\n",
      "Epoch 20/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8641 - loss: 0.4772 - val_accuracy: 0.8866 - val_loss: 0.4957\n",
      "Epoch 21/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8640 - loss: 0.4537 - val_accuracy: 0.9572 - val_loss: 0.3833\n",
      "Epoch 22/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.4111 - val_accuracy: 0.9752 - val_loss: 0.3439\n",
      "Epoch 23/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8798 - loss: 0.3821 - val_accuracy: 0.9174 - val_loss: 0.3725\n",
      "Epoch 24/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8475 - loss: 0.3872 - val_accuracy: 0.9324 - val_loss: 0.3118\n",
      "Epoch 25/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8611 - loss: 0.3506 - val_accuracy: 0.9707 - val_loss: 0.2872\n",
      "Epoch 26/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.3395 - val_accuracy: 0.9354 - val_loss: 0.2717\n",
      "Epoch 27/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.3578 - val_accuracy: 0.8964 - val_loss: 0.3537\n",
      "Epoch 28/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.3049 - val_accuracy: 0.9737 - val_loss: 0.2074\n",
      "Epoch 29/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8837 - loss: 0.2839 - val_accuracy: 0.9985 - val_loss: 0.1961\n",
      "Epoch 30/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8805 - loss: 0.2720 - val_accuracy: 0.9722 - val_loss: 0.1743\n",
      "Epoch 31/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8854 - loss: 0.2595 - val_accuracy: 0.9842 - val_loss: 0.1445\n",
      "Epoch 32/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8629 - loss: 0.2861 - val_accuracy: 0.9520 - val_loss: 0.2060\n",
      "Epoch 33/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8890 - loss: 0.2306 - val_accuracy: 0.9872 - val_loss: 0.1320\n",
      "Epoch 34/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8838 - loss: 0.2462 - val_accuracy: 0.9797 - val_loss: 0.1245\n",
      "Epoch 35/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8839 - loss: 0.2496 - val_accuracy: 0.9580 - val_loss: 0.1268\n",
      "Epoch 36/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8699 - loss: 0.2596 - val_accuracy: 0.9992 - val_loss: 0.0875\n",
      "Epoch 37/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.2081 - val_accuracy: 1.0000 - val_loss: 0.1003\n",
      "Epoch 38/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.1951 - val_accuracy: 0.9842 - val_loss: 0.1407\n",
      "Epoch 39/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2171 - val_accuracy: 1.0000 - val_loss: 0.0623\n",
      "Epoch 40/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.1593 - val_accuracy: 0.9677 - val_loss: 0.1586\n",
      "Epoch 41/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2263 - val_accuracy: 0.9610 - val_loss: 0.1364\n",
      "Epoch 42/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.1680 - val_accuracy: 0.9767 - val_loss: 0.0749\n",
      "Epoch 43/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.1738 - val_accuracy: 0.9715 - val_loss: 0.1474\n",
      "Epoch 44/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1693 - val_accuracy: 0.9715 - val_loss: 0.0759\n",
      "Epoch 45/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.1669 - val_accuracy: 0.9992 - val_loss: 0.0294\n",
      "Epoch 46/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.1849 - val_accuracy: 0.9812 - val_loss: 0.0814\n",
      "Epoch 47/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1314 - val_accuracy: 0.9602 - val_loss: 0.0626\n",
      "Epoch 48/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.1528 - val_accuracy: 1.0000 - val_loss: 0.0492\n",
      "Epoch 49/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1770 - val_accuracy: 0.9790 - val_loss: 0.2038\n",
      "Epoch 50/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8810 - loss: 0.2423 - val_accuracy: 0.9722 - val_loss: 0.0943\n",
      "Epoch 51/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.1645 - val_accuracy: 1.0000 - val_loss: 0.0438\n",
      "Epoch 52/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.1241 - val_accuracy: 0.9580 - val_loss: 0.0979\n",
      "Epoch 53/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.1440 - val_accuracy: 0.9752 - val_loss: 0.1307\n",
      "Epoch 54/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9367 - loss: 0.1589 - val_accuracy: 0.9535 - val_loss: 0.1007\n",
      "Epoch 55/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.1517 - val_accuracy: 0.9902 - val_loss: 0.0982\n",
      "Epoch 56/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.1449 - val_accuracy: 0.9309 - val_loss: 0.2595\n",
      "Epoch 57/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.1898 - val_accuracy: 0.9827 - val_loss: 0.1037\n",
      "Epoch 58/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.1769 - val_accuracy: 0.9557 - val_loss: 0.1009\n",
      "Epoch 59/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.1843 - val_accuracy: 1.0000 - val_loss: 0.0266\n",
      "Epoch 60/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.1404 - val_accuracy: 0.9287 - val_loss: 0.1804\n",
      "Epoch 61/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.1984 - val_accuracy: 0.9970 - val_loss: 0.0753\n",
      "Epoch 62/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1307 - val_accuracy: 0.9745 - val_loss: 0.0798\n",
      "Epoch 63/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.0986 - val_accuracy: 0.9977 - val_loss: 0.0380\n",
      "Epoch 64/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1139 - val_accuracy: 0.9722 - val_loss: 0.0741\n",
      "Epoch 65/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1054 - val_accuracy: 0.9805 - val_loss: 0.0579\n",
      "Epoch 66/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1242 - val_accuracy: 0.9692 - val_loss: 0.1013\n",
      "Epoch 67/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.1502 - val_accuracy: 0.9339 - val_loss: 0.1907\n",
      "Epoch 68/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.1667 - val_accuracy: 0.9992 - val_loss: 0.0490\n",
      "Epoch 69/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.0973 - val_accuracy: 1.0000 - val_loss: 0.0189\n",
      "Epoch 70/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.1713 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
      "Epoch 71/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9652 - loss: 0.0901 - val_accuracy: 0.9910 - val_loss: 0.0458\n",
      "Epoch 72/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1245 - val_accuracy: 0.9715 - val_loss: 0.0619\n",
      "Epoch 73/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1080 - val_accuracy: 0.9812 - val_loss: 0.0557\n",
      "Epoch 74/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1075 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
      "Epoch 75/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9627 - loss: 0.0921 - val_accuracy: 0.9347 - val_loss: 0.1868\n",
      "Epoch 76/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.1520 - val_accuracy: 0.9752 - val_loss: 0.0670\n",
      "Epoch 77/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.1183 - val_accuracy: 0.9797 - val_loss: 0.0803\n",
      "Epoch 78/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9248 - loss: 0.1791 - val_accuracy: 0.9730 - val_loss: 0.0508\n",
      "Epoch 79/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.0947 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "Epoch 80/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0664 - val_accuracy: 0.9722 - val_loss: 0.0449\n",
      "Epoch 81/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.1452 - val_accuracy: 0.9287 - val_loss: 0.1254\n",
      "Epoch 82/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1423 - val_accuracy: 0.9992 - val_loss: 0.0199\n",
      "Epoch 83/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1276 - val_accuracy: 0.9872 - val_loss: 0.0207\n",
      "Epoch 84/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.0891 - val_accuracy: 0.9850 - val_loss: 0.0375\n",
      "Epoch 85/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1305 - val_accuracy: 0.9775 - val_loss: 0.0738\n",
      "Epoch 86/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.1504 - val_accuracy: 0.9520 - val_loss: 0.1051\n",
      "Epoch 87/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1697 - val_accuracy: 0.9339 - val_loss: 0.1240\n",
      "Epoch 88/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1153 - val_accuracy: 0.9737 - val_loss: 0.0813\n",
      "Epoch 89/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1191 - val_accuracy: 0.9820 - val_loss: 0.0433\n",
      "Epoch 90/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1475 - val_accuracy: 0.9505 - val_loss: 0.0991\n",
      "Epoch 91/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.0984 - val_accuracy: 0.9557 - val_loss: 0.1024\n",
      "Epoch 92/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.0978 - val_accuracy: 0.9985 - val_loss: 0.0496\n",
      "Epoch 93/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.1988 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
      "Epoch 94/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.1365 - val_accuracy: 0.9242 - val_loss: 0.1152\n",
      "Epoch 95/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.1464 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 96/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9745 - loss: 0.0661 - val_accuracy: 0.9497 - val_loss: 0.0885\n",
      "Epoch 97/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.0816 - val_accuracy: 0.9722 - val_loss: 0.0689\n",
      "Epoch 98/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1072 - val_accuracy: 0.9865 - val_loss: 0.0441\n",
      "Epoch 99/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1119 - val_accuracy: 0.9722 - val_loss: 0.0600\n",
      "Epoch 100/100\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9747 - loss: 0.0742 - val_accuracy: 0.9407 - val_loss: 0.0702\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo GRU\n",
    "history_gru = model_gru.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db029f-4a19-4ad0-8f5d-740a8a472321",
   "metadata": {},
   "source": [
    "### Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3bcbf2e-7dd0-404f-ad1e-d6166888f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,651</span> (80.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,651\u001b[0m (80.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,651</span> (80.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,651\u001b[0m (80.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir o modelo LSTM\n",
    "model_lstm = Sequential()  # Cria um modelo sequencial para o LSTM\n",
    "\n",
    "# Camada LSTM\n",
    "model_lstm.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))  \n",
    "# Adiciona uma camada LSTM com 50 unidades. A forma de entrada é (n timesteps, n características)\n",
    "\n",
    "model_lstm.add(Dropout(0.2))  \n",
    "# Adiciona uma camada Dropout para prevenir overfitting, desativando aleatoriamente 20% dos neurônios durante o treinamento\n",
    "\n",
    "# Camada de saída\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))  \n",
    "# Adiciona uma camada densa de saída com 1 neurônio e ativação sigmoide para uma tarefa de classificação binária\n",
    "\n",
    "# Compilar o modelo\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "# Compila o modelo usando o otimizador Adam com taxa de aprendizado de 0.001, a função de perda de entropia cruzada binária e a métrica de acurácia\n",
    "\n",
    "# Resumo do modelo\n",
    "model_lstm.summary()  # Exibe um resumo da arquitetura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c05eafc9-416c-49fe-bd21-b6e86a903588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5734 - loss: 0.6768 - val_accuracy: 0.6291 - val_loss: 0.6633\n",
      "Epoch 2/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6417 - loss: 0.6506 - val_accuracy: 0.8191 - val_loss: 0.6087\n",
      "Epoch 3/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7311 - loss: 0.6087 - val_accuracy: 0.8829 - val_loss: 0.5740\n",
      "Epoch 4/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7708 - loss: 0.5794 - val_accuracy: 0.9640 - val_loss: 0.5284\n",
      "Epoch 5/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7775 - loss: 0.5541 - val_accuracy: 0.9279 - val_loss: 0.4762\n",
      "Epoch 6/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8469 - loss: 0.4853 - val_accuracy: 0.9407 - val_loss: 0.4288\n",
      "Epoch 7/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8489 - loss: 0.4424 - val_accuracy: 0.7860 - val_loss: 0.4905\n",
      "Epoch 8/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7805 - loss: 0.4707 - val_accuracy: 0.9782 - val_loss: 0.3591\n",
      "Epoch 9/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8657 - loss: 0.3724 - val_accuracy: 0.9505 - val_loss: 0.3230\n",
      "Epoch 10/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8898 - loss: 0.3295 - val_accuracy: 0.9692 - val_loss: 0.2911\n",
      "Epoch 11/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.3272 - val_accuracy: 0.9497 - val_loss: 0.3003\n",
      "Epoch 12/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8769 - loss: 0.3263 - val_accuracy: 0.9572 - val_loss: 0.2334\n",
      "Epoch 13/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9243 - loss: 0.2552 - val_accuracy: 0.9812 - val_loss: 0.1844\n",
      "Epoch 14/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.2351 - val_accuracy: 0.9700 - val_loss: 0.2618\n",
      "Epoch 15/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9287 - loss: 0.2458 - val_accuracy: 0.9992 - val_loss: 0.1850\n",
      "Epoch 16/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9533 - loss: 0.2098 - val_accuracy: 0.9384 - val_loss: 0.1840\n",
      "Epoch 17/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.2052 - val_accuracy: 0.9745 - val_loss: 0.1695\n",
      "Epoch 18/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2000 - val_accuracy: 0.9377 - val_loss: 0.1515\n",
      "Epoch 19/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1775 - val_accuracy: 0.9287 - val_loss: 0.1810\n",
      "Epoch 20/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1949 - val_accuracy: 0.9790 - val_loss: 0.1148\n",
      "Epoch 21/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1643 - val_accuracy: 0.9550 - val_loss: 0.1331\n",
      "Epoch 22/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1716 - val_accuracy: 0.9842 - val_loss: 0.0928\n",
      "Epoch 23/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1578 - val_accuracy: 0.9459 - val_loss: 0.1426\n",
      "Epoch 24/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9566 - loss: 0.1517 - val_accuracy: 0.9257 - val_loss: 0.2404\n",
      "Epoch 25/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1738 - val_accuracy: 0.9339 - val_loss: 0.1445\n",
      "Epoch 26/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.1725 - val_accuracy: 0.9827 - val_loss: 0.0684\n",
      "Epoch 27/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1522 - val_accuracy: 0.9797 - val_loss: 0.0793\n",
      "Epoch 28/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1403 - val_accuracy: 0.9572 - val_loss: 0.1321\n",
      "Epoch 29/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9565 - loss: 0.1437 - val_accuracy: 1.0000 - val_loss: 0.0558\n",
      "Epoch 30/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9556 - loss: 0.1440 - val_accuracy: 0.9324 - val_loss: 0.2287\n",
      "Epoch 31/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1749 - val_accuracy: 0.9865 - val_loss: 0.0513\n",
      "Epoch 32/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1462 - val_accuracy: 0.9745 - val_loss: 0.0771\n",
      "Epoch 33/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.1076 - val_accuracy: 1.0000 - val_loss: 0.0402\n",
      "Epoch 34/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.1079 - val_accuracy: 0.9865 - val_loss: 0.0730\n",
      "Epoch 35/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.1100 - val_accuracy: 0.9677 - val_loss: 0.0981\n",
      "Epoch 36/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1109 - val_accuracy: 0.9760 - val_loss: 0.0537\n",
      "Epoch 37/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9679 - loss: 0.0859 - val_accuracy: 0.9752 - val_loss: 0.0826\n",
      "Epoch 38/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1307 - val_accuracy: 0.9857 - val_loss: 0.0854\n",
      "Epoch 39/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.1571 - val_accuracy: 0.9700 - val_loss: 0.0744\n",
      "Epoch 40/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9574 - loss: 0.1170 - val_accuracy: 0.9782 - val_loss: 0.0616\n",
      "Epoch 41/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0947 - val_accuracy: 0.9865 - val_loss: 0.0705\n",
      "Epoch 42/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1256 - val_accuracy: 0.9992 - val_loss: 0.0420\n",
      "Epoch 43/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9735 - loss: 0.0747 - val_accuracy: 0.9925 - val_loss: 0.0495\n",
      "Epoch 44/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.0990 - val_accuracy: 0.9339 - val_loss: 0.2175\n",
      "Epoch 45/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1339 - val_accuracy: 0.9572 - val_loss: 0.0964\n",
      "Epoch 46/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1016 - val_accuracy: 0.9354 - val_loss: 0.0798\n",
      "Epoch 47/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1164 - val_accuracy: 0.9812 - val_loss: 0.0937\n",
      "Epoch 48/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.1215 - val_accuracy: 0.9992 - val_loss: 0.0614\n",
      "Epoch 49/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1365 - val_accuracy: 0.9872 - val_loss: 0.0475\n",
      "Epoch 50/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9770 - loss: 0.0751 - val_accuracy: 0.9722 - val_loss: 0.0990\n",
      "Epoch 51/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.0904 - val_accuracy: 0.9820 - val_loss: 0.0583\n",
      "Epoch 52/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1044 - val_accuracy: 0.9324 - val_loss: 0.0776\n",
      "Epoch 53/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9644 - loss: 0.0833 - val_accuracy: 0.9565 - val_loss: 0.1176\n",
      "Epoch 54/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9661 - loss: 0.0992 - val_accuracy: 0.9947 - val_loss: 0.0350\n",
      "Epoch 55/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.1031 - val_accuracy: 0.9474 - val_loss: 0.1197\n",
      "Epoch 56/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1218 - val_accuracy: 0.9655 - val_loss: 0.0793\n",
      "Epoch 57/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.0929 - val_accuracy: 0.9865 - val_loss: 0.0874\n",
      "Epoch 58/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1213 - val_accuracy: 0.9857 - val_loss: 0.0520\n",
      "Epoch 59/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0770 - val_accuracy: 0.9309 - val_loss: 0.1107\n",
      "Epoch 60/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9656 - loss: 0.0891 - val_accuracy: 0.9857 - val_loss: 0.0793\n",
      "Epoch 61/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9613 - loss: 0.0887 - val_accuracy: 0.9767 - val_loss: 0.0534\n",
      "Epoch 62/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.0863 - val_accuracy: 0.9812 - val_loss: 0.0680\n",
      "Epoch 63/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.0903 - val_accuracy: 0.9872 - val_loss: 0.0430\n",
      "Epoch 64/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9766 - loss: 0.0783 - val_accuracy: 0.9775 - val_loss: 0.0879\n",
      "Epoch 65/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1357 - val_accuracy: 0.9287 - val_loss: 0.1017\n",
      "Epoch 66/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9179 - loss: 0.1876 - val_accuracy: 0.9797 - val_loss: 0.0650\n",
      "Epoch 67/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1357 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
      "Epoch 68/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0892 - val_accuracy: 0.9550 - val_loss: 0.0716\n",
      "Epoch 69/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.1031 - val_accuracy: 0.9677 - val_loss: 0.0883\n",
      "Epoch 70/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1269 - val_accuracy: 0.9842 - val_loss: 0.0684\n",
      "Epoch 71/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9199 - loss: 0.1982 - val_accuracy: 0.9992 - val_loss: 0.0236\n",
      "Epoch 72/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1129 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
      "Epoch 73/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.1089 - val_accuracy: 0.9835 - val_loss: 0.0497\n",
      "Epoch 74/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1179 - val_accuracy: 0.9992 - val_loss: 0.0369\n",
      "Epoch 75/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1023 - val_accuracy: 1.0000 - val_loss: 0.0357\n",
      "Epoch 76/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.1011 - val_accuracy: 0.9617 - val_loss: 0.0640\n",
      "Epoch 77/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.0814 - val_accuracy: 0.9797 - val_loss: 0.0400\n",
      "Epoch 78/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9770 - loss: 0.0849 - val_accuracy: 0.9872 - val_loss: 0.0609\n",
      "Epoch 79/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1263 - val_accuracy: 0.9857 - val_loss: 0.0642\n",
      "Epoch 80/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1075 - val_accuracy: 0.9347 - val_loss: 0.1195\n",
      "Epoch 81/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.1043 - val_accuracy: 1.0000 - val_loss: 0.0409\n",
      "Epoch 82/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9640 - loss: 0.1101 - val_accuracy: 0.9797 - val_loss: 0.0364\n",
      "Epoch 83/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9763 - loss: 0.0742 - val_accuracy: 0.9797 - val_loss: 0.0401\n",
      "Epoch 84/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1535 - val_accuracy: 0.9737 - val_loss: 0.1112\n",
      "Epoch 85/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2119 - val_accuracy: 0.9992 - val_loss: 0.0718\n",
      "Epoch 86/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.1002 - val_accuracy: 0.9782 - val_loss: 0.0692\n",
      "Epoch 87/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9679 - loss: 0.0959 - val_accuracy: 1.0000 - val_loss: 0.0197\n",
      "Epoch 88/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9734 - loss: 0.0781 - val_accuracy: 0.9857 - val_loss: 0.0508\n",
      "Epoch 89/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0711 - val_accuracy: 0.9324 - val_loss: 0.1397\n",
      "Epoch 90/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1096 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
      "Epoch 91/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0833 - val_accuracy: 0.9685 - val_loss: 0.0696\n",
      "Epoch 92/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1077 - val_accuracy: 0.9977 - val_loss: 0.0328\n",
      "Epoch 93/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.0695 - val_accuracy: 0.9842 - val_loss: 0.0472\n",
      "Epoch 94/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1241 - val_accuracy: 0.9662 - val_loss: 0.0852\n",
      "Epoch 95/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9702 - loss: 0.0955 - val_accuracy: 0.9407 - val_loss: 0.1167\n",
      "Epoch 96/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1243 - val_accuracy: 0.9880 - val_loss: 0.0353\n",
      "Epoch 97/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1243 - val_accuracy: 0.9790 - val_loss: 0.0537\n",
      "Epoch 98/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.0995 - val_accuracy: 0.9977 - val_loss: 0.0611\n",
      "Epoch 99/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9755 - loss: 0.0794 - val_accuracy: 0.9655 - val_loss: 0.0793\n",
      "Epoch 100/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1027 - val_accuracy: 0.9384 - val_loss: 0.0800\n",
      "Epoch 101/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0798 - val_accuracy: 0.9865 - val_loss: 0.0451\n",
      "Epoch 102/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9762 - loss: 0.0627 - val_accuracy: 0.9857 - val_loss: 0.0295\n",
      "Epoch 103/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.1038 - val_accuracy: 0.9715 - val_loss: 0.1428\n",
      "Epoch 104/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2351 - val_accuracy: 0.9880 - val_loss: 0.0440\n",
      "Epoch 105/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.1311 - val_accuracy: 0.9715 - val_loss: 0.0623\n",
      "Epoch 106/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.0976 - val_accuracy: 0.9535 - val_loss: 0.0925\n",
      "Epoch 107/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9734 - loss: 0.0718 - val_accuracy: 0.9497 - val_loss: 0.0750\n",
      "Epoch 108/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1145 - val_accuracy: 0.9339 - val_loss: 0.1731\n",
      "Epoch 109/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9652 - loss: 0.1012 - val_accuracy: 0.9895 - val_loss: 0.0256\n",
      "Epoch 110/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9736 - loss: 0.0683 - val_accuracy: 0.9474 - val_loss: 0.0807\n",
      "Epoch 111/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.0948 - val_accuracy: 0.9932 - val_loss: 0.0244\n",
      "Epoch 112/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9635 - loss: 0.0860 - val_accuracy: 0.9835 - val_loss: 0.0425\n",
      "Epoch 113/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9579 - loss: 0.1022 - val_accuracy: 0.9850 - val_loss: 0.0593\n",
      "Epoch 114/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9614 - loss: 0.1074 - val_accuracy: 0.9865 - val_loss: 0.0739\n",
      "Epoch 115/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1532 - val_accuracy: 0.9730 - val_loss: 0.0399\n",
      "Epoch 116/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0628 - val_accuracy: 0.9512 - val_loss: 0.1119\n",
      "Epoch 117/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1087 - val_accuracy: 0.9767 - val_loss: 0.0434\n",
      "Epoch 118/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9758 - loss: 0.0762 - val_accuracy: 0.9775 - val_loss: 0.0742\n",
      "Epoch 119/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9749 - loss: 0.0731 - val_accuracy: 0.9835 - val_loss: 0.0421\n",
      "Epoch 120/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0664 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
      "Epoch 121/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0587 - val_accuracy: 0.9895 - val_loss: 0.0263\n",
      "Epoch 122/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9757 - loss: 0.0817 - val_accuracy: 1.0000 - val_loss: 0.0189\n",
      "Epoch 123/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.0854 - val_accuracy: 0.9872 - val_loss: 0.0477\n",
      "Epoch 124/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.1047 - val_accuracy: 0.9444 - val_loss: 0.0784\n",
      "Epoch 125/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1326 - val_accuracy: 0.9850 - val_loss: 0.0590\n",
      "Epoch 126/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1162 - val_accuracy: 0.9992 - val_loss: 0.0352\n",
      "Epoch 127/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9749 - loss: 0.0782 - val_accuracy: 0.9782 - val_loss: 0.0665\n",
      "Epoch 128/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1063 - val_accuracy: 0.9887 - val_loss: 0.0541\n",
      "Epoch 129/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0644 - val_accuracy: 0.9865 - val_loss: 0.0408\n",
      "Epoch 130/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0736 - val_accuracy: 1.0000 - val_loss: 0.0203\n",
      "Epoch 131/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0724 - val_accuracy: 0.9850 - val_loss: 0.0373\n",
      "Epoch 132/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.0894 - val_accuracy: 0.9752 - val_loss: 0.0640\n",
      "Epoch 133/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.0860 - val_accuracy: 0.9737 - val_loss: 0.0650\n",
      "Epoch 134/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0672 - val_accuracy: 0.9715 - val_loss: 0.0480\n",
      "Epoch 135/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9775 - loss: 0.0656 - val_accuracy: 0.9459 - val_loss: 0.0814\n",
      "Epoch 136/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.0861 - val_accuracy: 0.9977 - val_loss: 0.0223\n",
      "Epoch 137/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9674 - loss: 0.0763 - val_accuracy: 0.9730 - val_loss: 0.0592\n",
      "Epoch 138/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1194 - val_accuracy: 0.9835 - val_loss: 0.0456\n",
      "Epoch 139/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0717 - val_accuracy: 0.9947 - val_loss: 0.0540\n",
      "Epoch 140/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0972 - val_accuracy: 1.0000 - val_loss: 0.0117\n",
      "Epoch 141/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.0645 - val_accuracy: 0.9865 - val_loss: 0.0410\n",
      "Epoch 142/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0736 - val_accuracy: 1.0000 - val_loss: 0.0281\n",
      "Epoch 143/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0761 - val_accuracy: 0.9865 - val_loss: 0.0574\n",
      "Epoch 144/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1043 - val_accuracy: 0.9797 - val_loss: 0.0500\n",
      "Epoch 145/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9736 - loss: 0.0844 - val_accuracy: 0.9782 - val_loss: 0.0773\n",
      "Epoch 146/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.0844 - val_accuracy: 1.0000 - val_loss: 0.0092\n",
      "Epoch 147/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0278 - val_accuracy: 0.9489 - val_loss: 0.0555\n",
      "Epoch 148/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0894 - val_accuracy: 0.9745 - val_loss: 0.0623\n",
      "Epoch 149/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9539 - loss: 0.1223 - val_accuracy: 0.9737 - val_loss: 0.0649\n",
      "Epoch 150/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1368 - val_accuracy: 0.9647 - val_loss: 0.1032\n",
      "Epoch 151/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.1770 - val_accuracy: 0.9722 - val_loss: 0.0713\n",
      "Epoch 152/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1796 - val_accuracy: 0.9917 - val_loss: 0.0358\n",
      "Epoch 153/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1568 - val_accuracy: 0.9655 - val_loss: 0.1410\n",
      "Epoch 154/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2098 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
      "Epoch 155/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1453 - val_accuracy: 0.9437 - val_loss: 0.1213\n",
      "Epoch 156/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1204 - val_accuracy: 0.9797 - val_loss: 0.0332\n",
      "Epoch 157/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 0.0732 - val_accuracy: 0.9842 - val_loss: 0.0281\n",
      "Epoch 158/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1037 - val_accuracy: 0.9715 - val_loss: 0.0596\n",
      "Epoch 159/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.0791 - val_accuracy: 0.9985 - val_loss: 0.0206\n",
      "Epoch 160/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.0998 - val_accuracy: 0.9767 - val_loss: 0.0500\n",
      "Epoch 161/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0600 - val_accuracy: 1.0000 - val_loss: 0.0285\n",
      "Epoch 162/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.0909 - val_accuracy: 0.9887 - val_loss: 0.0328\n",
      "Epoch 163/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.1085 - val_accuracy: 0.9865 - val_loss: 0.0397\n",
      "Epoch 164/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.0967 - val_accuracy: 0.9992 - val_loss: 0.0234\n",
      "Epoch 165/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0850 - val_accuracy: 0.9722 - val_loss: 0.0670\n",
      "Epoch 166/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9345 - loss: 0.1625 - val_accuracy: 0.9865 - val_loss: 0.0514\n",
      "Epoch 167/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.0713 - val_accuracy: 0.9707 - val_loss: 0.0453\n",
      "Epoch 168/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9770 - loss: 0.0691 - val_accuracy: 0.9437 - val_loss: 0.1103\n",
      "Epoch 169/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.0743 - val_accuracy: 0.9857 - val_loss: 0.0591\n",
      "Epoch 170/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9655 - loss: 0.1034 - val_accuracy: 0.9992 - val_loss: 0.0103\n",
      "Epoch 171/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0808 - val_accuracy: 0.9309 - val_loss: 0.1434\n",
      "Epoch 172/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1072 - val_accuracy: 0.9302 - val_loss: 0.0843\n",
      "Epoch 173/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1244 - val_accuracy: 0.9362 - val_loss: 0.0955\n",
      "Epoch 174/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1037 - val_accuracy: 0.9865 - val_loss: 0.0537\n",
      "Epoch 175/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9756 - loss: 0.0726 - val_accuracy: 0.9392 - val_loss: 0.1046\n",
      "Epoch 176/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0775 - val_accuracy: 1.0000 - val_loss: 0.0208\n",
      "Epoch 177/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0604 - val_accuracy: 0.9797 - val_loss: 0.0385\n",
      "Epoch 178/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.0608 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
      "Epoch 179/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9795 - loss: 0.0634 - val_accuracy: 1.0000 - val_loss: 0.0274\n",
      "Epoch 180/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.0743 - val_accuracy: 0.9962 - val_loss: 0.0310\n",
      "Epoch 181/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1140 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
      "Epoch 182/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1252 - val_accuracy: 0.9339 - val_loss: 0.0961\n",
      "Epoch 183/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1372 - val_accuracy: 0.9640 - val_loss: 0.0656\n",
      "Epoch 184/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.0973 - val_accuracy: 0.9339 - val_loss: 0.1186\n",
      "Epoch 185/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1310 - val_accuracy: 0.9797 - val_loss: 0.0643\n",
      "Epoch 186/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1621 - val_accuracy: 0.9339 - val_loss: 0.0822\n",
      "Epoch 187/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1112 - val_accuracy: 0.9992 - val_loss: 0.0220\n",
      "Epoch 188/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0610 - val_accuracy: 0.9992 - val_loss: 0.0353\n",
      "Epoch 189/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0732 - val_accuracy: 0.9737 - val_loss: 0.0678\n",
      "Epoch 190/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0584 - val_accuracy: 0.9677 - val_loss: 0.0788\n",
      "Epoch 191/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0815 - val_accuracy: 0.9737 - val_loss: 0.0486\n",
      "Epoch 192/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0370 - val_accuracy: 0.9910 - val_loss: 0.0386\n",
      "Epoch 193/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0865 - val_accuracy: 0.9865 - val_loss: 0.0569\n",
      "Epoch 194/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.1001 - val_accuracy: 0.9707 - val_loss: 0.0989\n",
      "Epoch 195/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0750 - val_accuracy: 0.9685 - val_loss: 0.0821\n",
      "Epoch 196/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0765 - val_accuracy: 0.9685 - val_loss: 0.0816\n",
      "Epoch 197/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9733 - loss: 0.0808 - val_accuracy: 1.0000 - val_loss: 0.0095\n",
      "Epoch 198/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9758 - loss: 0.0730 - val_accuracy: 0.9685 - val_loss: 0.0737\n",
      "Epoch 199/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.0887 - val_accuracy: 0.9685 - val_loss: 0.0570\n",
      "Epoch 200/200\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.0819 - val_accuracy: 0.9640 - val_loss: 0.0950\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo LSTM\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38966e17-13f4-4b10-b17a-54c1db1630c4",
   "metadata": {},
   "source": [
    "## Avaliando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f15b60-20f0-40c2-a42c-53faf4da7886",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b40bc0c2-f0e2-44c8-a0f6-96fa24e10ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9532 - loss: 0.0598\n",
      "Test Loss GRU: 0.06438901275396347\n",
      "Test Accuracy GRU: 0.9477477669715881\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95       841\n",
      "         1.0       1.00      0.89      0.94       824\n",
      "\n",
      "    accuracy                           0.95      1665\n",
      "   macro avg       0.95      0.95      0.95      1665\n",
      "weighted avg       0.95      0.95      0.95      1665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo GRU com os dados de teste\n",
    "loss_gru, accuracy_gru = model_gru.evaluate(X_test, y_test)\n",
    "print(f'Test Loss GRU: {loss_gru}')\n",
    "print(f'Test Accuracy GRU: {accuracy_gru}')\n",
    "\n",
    "# Fazer previsões com o modelo GRU\n",
    "y_pred_gru = model_gru.predict(X_test)\n",
    "y_pred_gru = (y_pred_gru > 0.5).astype(int)\n",
    "\n",
    "# Exibir o relatório de classificação\n",
    "print(classification_report(y_test, y_pred_gru))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafc2ab-a9ce-41fb-80fd-f888c785378d",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61fd51a9-532b-42a9-b8d9-fe744cc92c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.9537 - loss: 0.1107\n",
      "Test Loss LSTM: 0.09792882204055786\n",
      "Test Accuracy LSTM: 0.9615615606307983\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       841\n",
      "         1.0       1.00      0.92      0.96       824\n",
      "\n",
      "    accuracy                           0.96      1665\n",
      "   macro avg       0.96      0.96      0.96      1665\n",
      "weighted avg       0.96      0.96      0.96      1665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo LSTM com os dados de teste\n",
    "loss_lstm, accuracy_lstm = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Test Loss LSTM: {loss_lstm}')\n",
    "print(f'Test Accuracy LSTM: {accuracy_lstm}')\n",
    "\n",
    "# Fazer previsões com o modelo LSTM\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "y_pred_lstm = (y_pred_lstm > 0.5).astype(int)\n",
    "\n",
    "# Exibir o relatório de classificação\n",
    "print(classification_report(y_test, y_pred_lstm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
